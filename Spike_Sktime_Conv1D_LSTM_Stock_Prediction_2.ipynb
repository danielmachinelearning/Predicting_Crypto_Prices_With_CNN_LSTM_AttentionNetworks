{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-uE1CfIWaYi",
        "outputId": "50984fbd-92dc-4a31-ebf8-4f4e8bd5da77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitmex in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: bravado in /usr/local/lib/python3.10/dist-packages (from bitmex) (11.0.3)\n",
            "Requirement already satisfied: bravado-core>=5.16.1 in /usr/local/lib/python3.10/dist-packages (from bravado->bitmex) (6.1.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from bravado->bitmex) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from bravado->bitmex) (2.8.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from bravado->bitmex) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.17 in /usr/local/lib/python3.10/dist-packages (from bravado->bitmex) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from bravado->bitmex) (1.16.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.10/dist-packages (from bravado->bitmex) (3.19.3)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.10/dist-packages (from bravado->bitmex) (1.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from bravado->bitmex) (4.12.2)\n",
            "Requirement already satisfied: jsonref in /usr/local/lib/python3.10/dist-packages (from bravado-core>=5.16.1->bravado->bitmex) (1.1.0)\n",
            "Requirement already satisfied: jsonschema>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (4.23.0)\n",
            "Requirement already satisfied: swagger-spec-validator>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from bravado-core>=5.16.1->bravado->bitmex) (3.0.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from bravado-core>=5.16.1->bravado->bitmex) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.17->bravado->bitmex) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.17->bravado->bitmex) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.17->bravado->bitmex) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.17->bravado->bitmex) (2024.8.30)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.5.1->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.5.1->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.5.1->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.5.1->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (0.22.3)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (3.0.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>0.1.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (0.1.1)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (24.11.1)\n",
            "Requirement already satisfied: importlib-resources>=1.3 in /usr/local/lib/python3.10/dist-packages (from swagger-spec-validator>=2.0.1->bravado-core>=5.16.1->bravado->bitmex) (6.4.5)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from isoduration->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=2.5.1->bravado-core>=5.16.1->bravado->bitmex) (2.9.0.20241206)\n",
            "Requirement already satisfied: python-binance in /usr/local/lib/python3.10/dist-packages (1.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from python-binance) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from python-binance) (1.16.0)\n",
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.10/dist-packages (from python-binance) (1.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from python-binance) (3.11.9)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from python-binance) (14.1)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from python-binance) (3.21.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->python-binance) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->python-binance) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->python-binance) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->python-binance) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->python-binance) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->python-binance) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->python-binance) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->python-binance) (1.18.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from dateparser->python-binance) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateparser->python-binance) (2024.2)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser->python-binance) (2024.9.11)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser->python-binance) (5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->python-binance) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->python-binance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->python-binance) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->python-binance) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->python-binance) (4.12.2)\n",
            "Requirement already satisfied: keras_multi_head in /usr/local/lib/python3.10/dist-packages (0.29.0)\n",
            "Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.10/dist-packages (from keras_multi_head) (0.51.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-self-attention==0.51.0->keras_multi_head) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: sktime in /usr/local/lib/python3.10/dist-packages (0.34.1)\n",
            "Requirement already satisfied: joblib<1.5,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from sktime) (1.4.2)\n",
            "Requirement already satisfied: numpy<2.2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from sktime) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sktime) (24.2)\n",
            "Requirement already satisfied: pandas<2.3.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from sktime) (2.2.2)\n",
            "Requirement already satisfied: scikit-base<0.12.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from sktime) (0.11.0)\n",
            "Requirement already satisfied: scikit-learn<1.6.0,>=0.24 in /usr/local/lib/python3.10/dist-packages (from sktime) (1.5.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from sktime) (1.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=1.1->sktime) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=1.1->sktime) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=1.1->sktime) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.6.0,>=0.24->sktime) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=1.1->sktime) (1.16.0)\n",
            "Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.10/dist-packages (0.51.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-self-attention) (1.26.4)\n",
            "Requirement already satisfied: tsmoothie in /usr/local/lib/python3.10/dist-packages (1.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tsmoothie) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tsmoothie) (1.13.1)\n",
            "Requirement already satisfied: simdkalman in /usr/local/lib/python3.10/dist-packages (from tsmoothie) (1.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install bitmex\n",
        "!pip install python-binance\n",
        "!pip install keras_multi_head\n",
        "!pip install requests --upgrade\n",
        "!pip install sktime\n",
        "!pip install keras-self-attention\n",
        "!pip install tsmoothie"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import Sequential\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "from keras.layers import Conv1D, Dropout, AveragePooling1D, LSTM, RepeatVector, TimeDistributed, Dense\n",
        "#from keras.layers import Sequential, Conv1D, Dropout, AveragePooling1D, LSTM, RepeatVector, TimeDistributed, Dense, RootMeanSquaredError"
      ],
      "metadata": {
        "id": "-1XXBEZ58CKn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mZNLTSWc_jdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "734961bb-fc26-4820-8e0e-284878355e54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/swagger_spec_validator/validator20.py:49: SwaggerValidationWarning: Found \"$ref: #/definitions/UserPreferences\" with siblings that will be overwritten. See https://stackoverflow.com/a/48114924 for more information. (path #/definitions/User/properties/preferences)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# IMPORTS\n",
        "import requests\n",
        "import tsmoothie\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import os.path\n",
        "import time\n",
        "from bitmex import bitmex\n",
        "from binance.client import Client\n",
        "from datetime import timedelta, datetime\n",
        "from dateutil import parser\n",
        "from tqdm import tqdm_notebook #(Optional, used for progress-bars)\n",
        "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, QuantileTransformer, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras_multi_head import MultiHeadAttention\n",
        "import pandas\n",
        "from pandas_datareader import data as pdr\n",
        "import yfinance as yfin\n",
        "from keras import backend as K\n",
        "from sktime.transformations.series.boxcox import BoxCoxTransformer, LogTransformer\n",
        "from sktime.transformations.series.difference import Differencer\n",
        "from sktime.transformations.series.detrend import Deseasonalizer\n",
        "from sktime.transformations.series.detrend import Detrender\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "\n",
        "### API\n",
        "bitmex_api_key = 'QJztZ3vF61eSlyYdDe1xnCrL'    #Enter your own API-key here\n",
        "bitmex_api_secret = 'iV05s1WvMdagCcerBaW-OglyS5DR41KEM7ti148vG67-lwA7' #Enter your own API-secret here\n",
        "binance_api_key = 'buEUMq3Qo5LaTwCOKl4vFJG1fe9kCmJtOtXOaPlpr7wgtF3iwXiVC3yKPFLTviyO'    #Enter your own API-key here\n",
        "binance_api_secret = 'lpHoAXrM2n42H9W2cOlnQUD1zckp1v6PiaCjQuLdgoPrCJ4jaBA8NGHxDd4OodSA' #Enter your own API-secret here\n",
        "\n",
        "### CONSTANTS\n",
        "binsizes = {\"1m\": 1, \"5m\": 5, \"1h\": 60, \"1d\": 1440}\n",
        "batch_size = 1000\n",
        "bitmex_client = bitmex(test=False, api_key=bitmex_api_key, api_secret=bitmex_api_secret)\n",
        "#binance_client = Client(api_key=binance_api_key, api_secret=binance_api_secret)\n",
        "\n",
        "\n",
        "### FUNCTIONS\n",
        "def minutes_of_new_data(symbol, kline_size, data, source):\n",
        "    if len(data) > 0:  old = parser.parse(data[\"timestamp\"].iloc[-1])\n",
        "    elif source == \"binance\": old = datetime.strptime('1 Jan 2017', '%d %b %Y')\n",
        "    elif source == \"bitmex\": old = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=1, reverse=False).result()[0][0]['timestamp']\n",
        "    if source == \"binance\": new = pd.to_datetime(binance_client.get_klines(symbol=symbol, interval=kline_size)[-1][0], unit='ms')\n",
        "    if source == \"bitmex\": new = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=1, reverse=True).result()[0][0]['timestamp']\n",
        "    return old, new\n",
        "\n",
        "\n",
        "def get_crypto_price(symbol, exchange, start_date = None):\n",
        "    api_key = 'RC2YY8JWEUDMY6IW'\n",
        "    api_url = f'https://www.alphavantage.co/query?function=DIGITAL_CURRENCY_DAILY&symbol={symbol}&market={exchange}&apikey={api_key}'\n",
        "    raw_df = requests.get(api_url).json()\n",
        "    print(raw_df)\n",
        "    df = pd.DataFrame(raw_df['Time Series (Digital Currency Daily)']).T\n",
        "    df = df.rename(columns = {'1a. open (USD)': 'open', '2a. high (USD)': 'high', '3a. low (USD)': 'low', '4a. close (USD)': 'close', '5. volume': 'volume'})\n",
        "    for i in df.columns:\n",
        "        df[i] = df[i].astype(float)\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "    df = df.iloc[::-1].drop(['1b. open (USD)', '2b. high (USD)', '3b. low (USD)', '4b. close (USD)', '6. market cap (USD)'], axis = 1)\n",
        "    if start_date:\n",
        "        df = df[df.index >= start_date]\n",
        "    return df\n",
        "\n",
        "\n",
        "#def get_all_binance(symbol, kline_size, save = False):\n",
        "#    filename = '%s-%s-data.csv' % (symbol, kline_size)\n",
        "#    if os.path.isfile(filename): data_df = pd.read_csv(filename)\n",
        "#    else: data_df = pd.DataFrame()\n",
        "#    oldest_point, newest_point = minutes_of_new_data(symbol, kline_size, data_df, source = \"binance\")\n",
        "#    delta_min = (newest_point - oldest_point).total_seconds()/60\n",
        "#    available_data = math.ceil(delta_min/binsizes[kline_size])\n",
        "#    if oldest_point == datetime.strptime('1 Jan 2017', '%d %b %Y'): print('Downloading all available %s data for %s. Be patient..!' % (kline_size, symbol))\n",
        "#    else: print('Downloading %d minutes of new data available for %s, i.e. %d instances of %s data.' % (delta_min, symbol, available_data, kline_size))\n",
        "#    klines = binance_client.get_historical_klines(symbol, kline_size, oldest_point.strftime(\"%d %b %Y %H:%M:%S\"), newest_point.strftime(\"%d %b %Y %H:%M:%S\"))\n",
        "#    data = pd.DataFrame(klines, columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_av', 'trades', 'tb_base_av', 'tb_quote_av', 'ignore' ])\n",
        "#    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
        "#    if len(data_df) > 0:\n",
        "#        temp_df = pd.DataFrame(data)\n",
        "#        data_df = data_df.append(temp_df)\n",
        "#    else: data_df = data\n",
        "#    data_df.set_index('timestamp', inplace=True)\n",
        "#    if save: data_df.to_csv(filename)\n",
        "#    print('All caught up..!')\n",
        "#    return data_df\n",
        "\n",
        "def get_all_bitmex(symbol, kline_size, save = False):\n",
        "    filename = '%s-%s-data.csv' % (symbol, kline_size)\n",
        "    if os.path.isfile(filename): data_df = pd.read_csv(filename)\n",
        "    else: data_df = pd.DataFrame()\n",
        "    oldest_point, newest_point = minutes_of_new_data(symbol, kline_size, data_df, source = \"bitmex\")\n",
        "    delta_min = (newest_point - oldest_point).total_seconds()/60\n",
        "    available_data = math.ceil(delta_min/binsizes[kline_size])\n",
        "    rounds = math.ceil(available_data / batch_size)\n",
        "    if rounds > 0:\n",
        "        print('Downloading %d minutes of new data available for %s, i.e. %d instances of %s data in %d rounds.' % (delta_min, symbol, available_data, kline_size, rounds))\n",
        "        for round_num in tqdm_notebook(range(rounds)):\n",
        "            time.sleep(1)\n",
        "            new_time = (oldest_point + timedelta(minutes = round_num * batch_size * binsizes[kline_size]))\n",
        "            data = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=batch_size, startTime = new_time).result()[0]\n",
        "            temp_df = pd.DataFrame(data)\n",
        "            data_df = data_df.append(temp_df)\n",
        "    data_df.set_index('timestamp', inplace=True)\n",
        "    if save and rounds > 0: data_df.to_csv(filename)\n",
        "    print('All caught up..!')\n",
        "    return data_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aCGH2uvMY6US"
      },
      "outputs": [],
      "source": [
        "def split_series(series, n_past, n_future):\n",
        "  #\n",
        "  # n_past ==> no of past observations\n",
        "  #\n",
        "  # n_future ==> no of future observations\n",
        "  #\n",
        "  X, y = list(), list()\n",
        "  for window_start in range(len(series)):\n",
        "    past_end = window_start + n_past\n",
        "    future_end = past_end + n_future\n",
        "    if future_end > len(series):\n",
        "      break\n",
        "    # slicing the past and future parts of the window\n",
        "    past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
        "    X.append(past)\n",
        "    y.append(future)\n",
        "  return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WpXEgX6v0Vqd"
      },
      "outputs": [],
      "source": [
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get('loss') <= 1e-3:\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a-Xz1irGnAaG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tsmoothie.utils_func import sim_randomwalk\n",
        "from tsmoothie.smoother import LowessSmoother\n",
        "\n",
        "def getOutliers(stock, exchange, dict_output, lookback, startdate, enddate):\n",
        "  outlier_points = []\n",
        "\n",
        "  symbol = stock\n",
        "  crypto = stock + '-' + exchange\n",
        "  #yfin.pdr_override()\n",
        "  data = pdr.get_data_yahoo(crypto, start=startdate, end=enddate)\n",
        "  df = data[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
        "  df.columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
        "  eps = 1e-9\n",
        "  df['Open'] = df['Open'].astype('float32') + eps\n",
        "  df['High'] = df['High'].astype('float32') + eps\n",
        "  df['Low'] = df['Low'].astype('float32') + eps\n",
        "  df['Close'] = df['Close'].astype('float32') + eps\n",
        "  df['Adj Close'] = df['Adj Close'].astype('float32') + eps\n",
        "  df['Volume'] = df['Volume'].astype('float32') + eps\n",
        "\n",
        "  if len(df) < 20:\n",
        "    return\n",
        "\n",
        "  data = df['Adj Close'].values.reshape(1, -1)\n",
        "\n",
        "  # operate smoothing\n",
        "  smoother = LowessSmoother(smooth_fraction=0.1, iterations=1)\n",
        "  smoother.smooth(data)\n",
        "\n",
        "  # generate intervals\n",
        "  low, up = smoother.get_intervals('prediction_interval')\n",
        "\n",
        "  points = smoother.data[0]\n",
        "  up_points = up[0]\n",
        "  low_points = low[0]\n",
        "\n",
        "  for i in range(len(points)-1, 0, -1):\n",
        "      current_point = points[i]\n",
        "      current_up = up_points[i]\n",
        "      current_low = low_points[i]\n",
        "      if current_point > current_up or current_point < current_low:\n",
        "          outlier_points.append(i)\n",
        "          print(f'found an outlier value: {current_point}')\n",
        "\n",
        "  overall_points = list(set(list(range(len(df)))) - set(outlier_points))\n",
        "  print(overall_points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AQD5niGrVuYu"
      },
      "outputs": [],
      "source": [
        "def getFuturePrices(stock, exchange, dict_output, lookback, startdate, enddate):\n",
        "  outlier_points = []\n",
        "  symbol = stock\n",
        "  crypto = stock + '-' + exchange\n",
        "  #yfin.pdr_override()\n",
        "  #data = pdr.get_data_yahoo(crypto, start=startdate, end=enddate)\n",
        "  data = yfin.download(\n",
        "    tickers = crypto,\n",
        "    period = \"max\",\n",
        "    interval = \"15m\"\n",
        "    )\n",
        "  df = data[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']]\n",
        "  df.columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
        "  eps = 1e-9\n",
        "  df['Open'] = df['Open'].astype('float32') + eps\n",
        "  df['High'] = df['High'].astype('float32') + eps\n",
        "  df['Low'] = df['Low'].astype('float32') + eps\n",
        "  df['Close'] = df['Close'].astype('float32') + eps\n",
        "  df['Adj Close'] = df['Adj Close'].astype('float32') + eps\n",
        "  df['Volume'] = df['Volume'].astype('float32') + eps\n",
        "\n",
        "  one_hot1 = pd.get_dummies(pd.DatetimeIndex(df.index).month.astype('int'))\n",
        "  one_hot2 = pd.get_dummies(pd.DatetimeIndex(df.index).day.astype('int'))\n",
        "  # Drop column B as it is now encoded\n",
        "  # Join the encoded df\n",
        "  df = df.reset_index()\n",
        "  df = pd.concat([df, one_hot1, one_hot2], axis=1)\n",
        "  if(len(df) < lookback):\n",
        "    return(dict_output)\n",
        "  df = df.drop(\"Datetime\", axis=1)\n",
        "  print(df)\n",
        "\n",
        "  data = df['Adj Close'].values.reshape(1, -1)\n",
        "\n",
        "  # operate smoothing\n",
        "  smoother = LowessSmoother(smooth_fraction=0.1, iterations=1)\n",
        "  smoother.smooth(data)\n",
        "\n",
        "  # generate intervals\n",
        "  low, up = smoother.get_intervals('prediction_interval')\n",
        "\n",
        "  points = smoother.data[0]\n",
        "  up_points = up[0]\n",
        "  low_points = low[0]\n",
        "\n",
        "  for i in range(len(points)-1, 0, -1):\n",
        "      current_point = points[i]\n",
        "      current_up = up_points[i]\n",
        "      current_low = low_points[i]\n",
        "      if current_point > current_up or current_point < current_low:\n",
        "        for j in range(-1,1,1):\n",
        "          outlier_points.append(i+j)\n",
        "\n",
        "  overall_points = list(set(list(range(len(df)))) - set(outlier_points))\n",
        "  overall_df = df[df.reset_index().index.isin(overall_points)]\n",
        "  print(overall_df)\n",
        "\n",
        "  compare_df = pd.DataFrame()\n",
        "  compare_df['Actual'] = df[-120:]['Adj Close'].tolist()\n",
        "  print(compare_df)\n",
        "\n",
        "  train = overall_df[:(-1*lookback)-121]\n",
        "  scalers={}\n",
        "  for i in ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']:\n",
        "      scaler = Pipeline([('log', LogTransformer()), ('scaler', StandardScaler()), ('max', MinMaxScaler(feature_range=(-1,1)))]) #MinMaxScaler()\n",
        "      s_s = scaler.fit(df[:(-1*lookback)-121][i].values.reshape(-1,1))\n",
        "      s_s = scaler.transform(train[i].values.reshape(-1,1))\n",
        "      s_s=np.reshape(s_s,len(s_s))\n",
        "      scalers['scaler_'+ i] = scaler\n",
        "      train[i]=s_s\n",
        "  test = overall_df[(-1*lookback)-121:-120]\n",
        "  for i in ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']:\n",
        "      scaler = scalers['scaler_'+i]\n",
        "      s_s = scaler.transform(test[i].values.reshape(-1,1))\n",
        "      s_s=np.reshape(s_s,len(s_s))\n",
        "      scalers['scaler_'+i] = scaler\n",
        "      test[i]=s_s\n",
        "\n",
        "\n",
        "  n_past = lookback\n",
        "  n_future = 1\n",
        "  n_features = 6+len(one_hot1.columns)+len(one_hot2.columns)\n",
        "\n",
        "  X_train, y_train = split_series(train.values, n_past, n_future)\n",
        "  X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
        "  y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
        "  X_test, y_test = split_series(test.values, n_past, n_future)\n",
        "  X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n",
        "  y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))\n",
        "\n",
        "  X_train = np.asarray(X_train).astype('float32')\n",
        "  y_train = np.asarray(y_train).astype('float32')\n",
        "  X_test = np.asarray(X_test).astype('float32')\n",
        "  y_test = np.asarray(y_test).astype('float32')\n",
        "\n",
        "  model_e1d1 = Sequential()\n",
        "  model_e1d1.add(Conv1D(filters=256, kernel_size=3,    # Standard 128\n",
        "                                strides=1, padding='causal',\n",
        "                                activation=\"relu\",\n",
        "                                input_shape=(None, n_features)))\n",
        "  model_e1d1.add(Dropout(0.2))\n",
        "  model_e1d1.add(AveragePooling1D(pool_size=3))\n",
        "  model_e1d1.add(Conv1D(filters=256, kernel_size=3,    # Standard 128\n",
        "                                strides=1, padding='causal',\n",
        "                                activation=\"relu\",\n",
        "                                input_shape=(None, n_features)))\n",
        "  model_e1d1.add(Dropout(0.2))\n",
        "  model_e1d1.add(AveragePooling1D(pool_size=3))\n",
        "  model_e1d1.add(LSTM(1000, dropout=0.2, recurrent_dropout=0.2, input_shape=(n_past, n_features)))\n",
        "  model_e1d1.add(RepeatVector(n_future))\n",
        "  model_e1d1.add(MultiHeadAttention(\n",
        "      head_num=5,\n",
        "      name='Multi-Head',\n",
        "  ))\n",
        "  model_e1d1.add(LSTM(1000, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "  model_e1d1.add(TimeDistributed(Dense(n_features, activation='linear')))\n",
        "  #model_e1d1.load_weights(\"original_dataset_power_new_2.h5\")\n",
        "  model_e1d1.summary()\n",
        "\n",
        "  x = 1000\n",
        "  y = 2e-3\n",
        "  z = 1\n",
        "  #optimizer = keras.optimizers.Adamax(lr=x*y*z)\n",
        "  model_checkpoint_callback_e1d1 = tf.keras.callbacks.ModelCheckpoint(filepath=\"original_dataset_power_new_2.weights.h5\", save_weights_only=True, monitor='root_mean_squared_error',save_best_only=True)\n",
        "  callback = keras.callbacks.EarlyStopping(monitor='root_mean_squared_error', min_delta=0.001, patience=10000)\n",
        "  reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: y * z ** x)\n",
        "  model_e1d1.compile(optimizer='Adam', loss='mse', metrics=[RootMeanSquaredError()])\n",
        "  history_e1d1=model_e1d1.fit(X_train,y_train,shuffle=False,epochs=200,validation_data=(X_test,y_test),batch_size=256,verbose=1,callbacks=[callback, reduce_lr, model_checkpoint_callback_e1d1])\n",
        "\n",
        "\n",
        "  test2 = X_test\n",
        "  final_values_non_spike = np.zeros(shape=(120,6+len(one_hot1.columns)+len(one_hot2.columns)))\n",
        "  for i in range(120):\n",
        "    pred_e1d1=model_e1d1.predict(test2)\n",
        "    for j in range(lookback):\n",
        "      if j != (lookback-1):\n",
        "        test2[0][j] = test2[0][j+1]\n",
        "      else:\n",
        "        test2[0][j] = pred_e1d1[0]\n",
        "\n",
        "    final_values_non_spike[i] = pred_e1d1[0]\n",
        "\n",
        "\n",
        "  final_values_non_spike = np.array([final_values_non_spike])\n",
        "\n",
        "  pred_e1d1 = final_values_non_spike\n",
        "  for index,i in enumerate(df.columns):\n",
        "    if i in ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']:\n",
        "      scaler = scalers['scaler_'+i]\n",
        "      pred_e1d1[:,:,index]=scaler.inverse_transform(pred_e1d1[:,:,index])\n",
        "      y_train[:,:,index]=scaler.inverse_transform(y_train[:,:,index])\n",
        "      y_test[:,:,index]=scaler.inverse_transform(y_test[:,:,index])\n",
        "\n",
        "  final_df = pd.DataFrame(pred_e1d1[0])\n",
        "\n",
        "  months = [i for i in range(len(one_hot1.columns))]\n",
        "  days = [i for i in range(len(one_hot2.columns))]\n",
        "  days_of_week = [i for i in range(2)]\n",
        "  final_df.columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'] + months + days\n",
        "  print(final_df)\n",
        "\n",
        "  compare_df['Predicted'] = final_df['Adj Close'].tolist()\n",
        "  print(compare_df)\n",
        "\n",
        "  dict_output[crypto] = (df['Adj Close'].iloc[-1], final_df['Adj Close'].max())\n",
        "\n",
        "  plt.plot(list(range(120)), compare_df['Actual'].tolist())\n",
        "  plt.plot(list(range(120)), compare_df['Predicted'].tolist())\n",
        "  plt.title('title')\n",
        "  plt.ylabel('ylabel')\n",
        "  plt.xlabel('xlabel')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  print(dict_output)\n",
        "  #return(dict_output)\n",
        "\n",
        "  spike_points = []\n",
        "  for i in outlier_points:\n",
        "    for j in range(-20,20,1):\n",
        "      spike_points.append(i+j)\n",
        "\n",
        "  spike_points = list(set(spike_points))\n",
        "  overall_points = spike_points\n",
        "  overall_df = df[df.reset_index().index.isin(overall_points)]\n",
        "\n",
        "\n",
        "  train = overall_df[:(-1*lookback)-1]\n",
        "  for i in ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']:\n",
        "      scaler = scalers['scaler_'+ i]\n",
        "      s_s = scaler.transform(train[i].values.reshape(-1,1))\n",
        "      s_s=np.reshape(s_s,len(s_s))\n",
        "      scalers['scaler_'+ i] = scaler\n",
        "      train[i]=s_s\n",
        "  test = overall_df[(-1*lookback)-1:]\n",
        "  for i in ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']:\n",
        "      sscaler = scalers['scaler_'+ i]\n",
        "      s_s = scaler.transform(test[i].values.reshape(-1,1))\n",
        "      s_s=np.reshape(s_s,len(s_s))\n",
        "      scalers['scaler_'+i] = scaler\n",
        "      test[i]=s_s\n",
        "\n",
        "  n_past = lookback\n",
        "  n_future = 1\n",
        "  n_features = 6+len(one_hot1.columns) + len(one_hot2.columns)\n",
        "\n",
        "  X_train, y_train = split_series(train.values, n_past, n_future)\n",
        "  X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
        "  y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
        "  X_test, y_test = split_series(test.values, n_past, n_future)\n",
        "  X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n",
        "  y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))\n",
        "\n",
        "  X_train = np.asarray(X_train).astype('float32')\n",
        "  y_train = np.asarray(y_train).astype('float32')\n",
        "  X_test = np.asarray(X_test).astype('float32')\n",
        "  y_test = np.asarray(y_test).astype('float32')\n",
        "\n",
        "  # E1D1\n",
        "  # n_features ==> no of features at each timestep in the data.\n",
        "  #\n",
        "  encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
        "  encoder_l1 = tf.keras.layers.LSTM(1500, dropout=0.2, recurrent_dropout=0.2, return_state=True)\n",
        "  encoder_outputs1 = encoder_l1(encoder_inputs)\n",
        "  encoder_states1 = encoder_outputs1[1:]\n",
        "  decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs1[0])\n",
        "  decoder_inputs1 = MultiHeadAttention(head_num=5) (decoder_inputs)\n",
        "  decoder_l1 = tf.keras.layers.LSTM(1500, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(decoder_inputs1, initial_state = encoder_states1)\n",
        "  decoder_outputs1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features, activation='linear'))(decoder_l1)\n",
        "  model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs1)\n",
        "  model_e2d2.summary()\n",
        "\n",
        "  reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
        "  model_e2d2.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())\n",
        "  history_e2d2=model_e1d1.fit(X_train,y_train,epochs=40,validation_data=(X_test,y_test),batch_size=256)\n",
        "\n",
        "\n",
        "  final_values = final_values_non_spike[0]\n",
        "  X_test, y_test = split_series(final_values[:31], n_past, n_future)\n",
        "  X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n",
        "  test2 = X_test\n",
        "  for i in range(lookback):\n",
        "    print(\"Called here\")\n",
        "    pred_e2d2=model_e2d2.predict(test2)\n",
        "    for j in range(lookback):\n",
        "      if j != (lookback-1):\n",
        "        test2[0][j] = test2[0][j+1]\n",
        "      else:\n",
        "        test2[0][j] = pred_e2d2[0]\n",
        "\n",
        "    final_values[i+lookback] = pred_e2d2[0]\n",
        "\n",
        "\n",
        "  final_values = np.array([final_values])\n",
        "\n",
        "  pred_e2d2 = final_values\n",
        "  for index,i in enumerate(df.columns):\n",
        "    if i in ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']:\n",
        "      scaler = scalers['scaler_'+i]\n",
        "      pred_e2d2[:,:,index]=scaler.inverse_transform(pred_e2d2[:,:,index])\n",
        "      y_train[:,:,index]=scaler.inverse_transform(y_train[:,:,index])\n",
        "      y_test[:,:,index]=scaler.inverse_transform(y_test[:,:,index])\n",
        "\n",
        "\n",
        "  final_df = pd.DataFrame(pred_e2d2[0])\n",
        "\n",
        "  months = [i for i in range(len(one_hot1.columns))]\n",
        "  days = [i for i in range(len(one_hot2.columns))]\n",
        "  days_of_week = [i for i in range(2)]\n",
        "  final_df.columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'] + months + days\n",
        "  print(final_df)\n",
        "\n",
        "  compare_df['Predicted'] = final_df['Adj Close'].tolist()\n",
        "  print(compare_df)\n",
        "\n",
        "  dict_output[crypto] = (df['Adj Close'].iloc[-1], final_df['Adj Close'].max())\n",
        "\n",
        "  plt.plot(list(range(120)), compare_df['Actual'].tolist())\n",
        "  plt.plot(list(range(120)), compare_df['Predicted'].tolist())\n",
        "  plt.title('title')\n",
        "  plt.ylabel('ylabel')\n",
        "  plt.xlabel('xlabel')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  print(dict_output)\n",
        "  #return(dict_output)\n",
        "\n",
        "  K.clear_session()\n",
        "  del model_e1d1\n",
        "  del model_e2d2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xHsQ01cDwM-2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2bf01ea0-d8ad-4415-ae8c-71eb40747ece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Open          High           Low         Close     Adj Close  \\\n",
            "0     8.625528e-08  8.625528e-08  8.613004e-08  8.613004e-08  8.613004e-08   \n",
            "1     8.617525e-08  8.630630e-08  8.617525e-08  8.630630e-08  8.630630e-08   \n",
            "2     8.631332e-08  8.636552e-08  8.626549e-08  8.636552e-08  8.636552e-08   \n",
            "3     8.641882e-08  8.641882e-08  8.633513e-08  8.637900e-08  8.637900e-08   \n",
            "4     8.626876e-08  8.632660e-08  8.624897e-08  8.632660e-08  8.632660e-08   \n",
            "...            ...           ...           ...           ...           ...   \n",
            "5754  2.962238e-07  2.972876e-07  2.962238e-07  2.970656e-07  2.970656e-07   \n",
            "5755  2.967699e-07  2.967699e-07  2.950631e-07  2.950631e-07  2.950631e-07   \n",
            "5756  2.956309e-07  2.986630e-07  2.956309e-07  2.986630e-07  2.986630e-07   \n",
            "5757  2.990153e-07  2.990153e-07  2.983086e-07  2.983086e-07  2.983086e-07   \n",
            "5758  2.966414e-07  2.966414e-07  2.954335e-07  2.954335e-07  2.954335e-07   \n",
            "\n",
            "            Volume     10     11     12      1  ...     22     23     24  \\\n",
            "0     1.000000e-09   True  False  False  False  ...  False  False  False   \n",
            "1     1.000000e-09   True  False  False  False  ...  False  False  False   \n",
            "2     1.000000e-09   True  False  False  False  ...  False  False  False   \n",
            "3     4.398000e+03   True  False  False  False  ...  False  False  False   \n",
            "4     1.000000e-09   True  False  False  False  ...  False  False  False   \n",
            "...            ...    ...    ...    ...    ...  ...    ...    ...    ...   \n",
            "5754  1.000000e-09  False  False   True  False  ...  False  False  False   \n",
            "5755  1.000000e-09  False  False   True  False  ...  False  False  False   \n",
            "5756  8.364000e+03  False  False   True  False  ...  False  False  False   \n",
            "5757  1.000000e-09  False  False   True  False  ...  False  False  False   \n",
            "5758  3.937000e+03  False  False   True  False  ...  False  False  False   \n",
            "\n",
            "         25     26     27     28     29     30     31  \n",
            "0     False  False  False  False  False  False  False  \n",
            "1     False  False  False  False  False  False  False  \n",
            "2     False  False  False  False  False  False  False  \n",
            "3     False  False  False  False  False  False  False  \n",
            "4     False  False  False  False  False  False  False  \n",
            "...     ...    ...    ...    ...    ...    ...    ...  \n",
            "5754  False  False  False  False  False  False  False  \n",
            "5755  False  False  False  False  False  False  False  \n",
            "5756  False  False  False  False  False  False  False  \n",
            "5757  False  False  False  False  False  False  False  \n",
            "5758  False  False  False  False  False  False  False  \n",
            "\n",
            "[5759 rows x 40 columns]\n",
            "              Open          High           Low         Close     Adj Close  \\\n",
            "0     8.625528e-08  8.625528e-08  8.613004e-08  8.613004e-08  8.613004e-08   \n",
            "1     8.617525e-08  8.630630e-08  8.617525e-08  8.630630e-08  8.630630e-08   \n",
            "2     8.631332e-08  8.636552e-08  8.626549e-08  8.636552e-08  8.636552e-08   \n",
            "3     8.641882e-08  8.641882e-08  8.633513e-08  8.637900e-08  8.637900e-08   \n",
            "4     8.626876e-08  8.632660e-08  8.624897e-08  8.632660e-08  8.632660e-08   \n",
            "...            ...           ...           ...           ...           ...   \n",
            "5728  3.167687e-07  3.192390e-07  3.167687e-07  3.192390e-07  3.192390e-07   \n",
            "5729  3.196578e-07  3.206270e-07  3.196578e-07  3.203323e-07  3.203323e-07   \n",
            "5730  3.200241e-07  3.218333e-07  3.200241e-07  3.218333e-07  3.218333e-07   \n",
            "5731  3.218303e-07  3.218303e-07  3.214206e-07  3.214206e-07  3.214206e-07   \n",
            "5732  3.205174e-07  3.205174e-07  3.204215e-07  3.204215e-07  3.204215e-07   \n",
            "\n",
            "            Volume     10     11     12      1  ...     22     23     24  \\\n",
            "0     1.000000e-09   True  False  False  False  ...  False  False  False   \n",
            "1     1.000000e-09   True  False  False  False  ...  False  False  False   \n",
            "2     1.000000e-09   True  False  False  False  ...  False  False  False   \n",
            "3     4.398000e+03   True  False  False  False  ...  False  False  False   \n",
            "4     1.000000e-09   True  False  False  False  ...  False  False  False   \n",
            "...            ...    ...    ...    ...    ...  ...    ...    ...    ...   \n",
            "5728  1.000000e-09  False  False   True  False  ...  False  False  False   \n",
            "5729  5.638000e+03  False  False   True  False  ...  False  False  False   \n",
            "5730  1.000000e-09  False  False   True  False  ...  False  False  False   \n",
            "5731  3.131000e+03  False  False   True  False  ...  False  False  False   \n",
            "5732  6.961000e+03  False  False   True  False  ...  False  False  False   \n",
            "\n",
            "         25     26     27     28     29     30     31  \n",
            "0     False  False  False  False  False  False  False  \n",
            "1     False  False  False  False  False  False  False  \n",
            "2     False  False  False  False  False  False  False  \n",
            "3     False  False  False  False  False  False  False  \n",
            "4     False  False  False  False  False  False  False  \n",
            "...     ...    ...    ...    ...    ...    ...    ...  \n",
            "5728  False  False  False  False  False  False  False  \n",
            "5729  False  False  False  False  False  False  False  \n",
            "5730  False  False  False  False  False  False  False  \n",
            "5731  False  False  False  False  False  False  False  \n",
            "5732  False  False  False  False  False  False  False  \n",
            "\n",
            "[5411 rows x 40 columns]\n",
            "           Actual\n",
            "0    3.052210e-07\n",
            "1    3.034849e-07\n",
            "2    3.009333e-07\n",
            "3    3.005540e-07\n",
            "4    2.962310e-07\n",
            "..            ...\n",
            "115  2.970656e-07\n",
            "116  2.950631e-07\n",
            "117  2.986630e-07\n",
            "118  2.983086e-07\n",
            "119  2.954335e-07\n",
            "\n",
            "[120 rows x 1 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d (\u001b[38;5;33mConv1D\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                     \u001b[38;5;34m30,976\u001b[0m \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " average_pooling1d (\u001b[38;5;33mAveragePooling1D\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                    \u001b[38;5;34m196,864\u001b[0m \n",
              "\n",
              " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " average_pooling1d_1                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mAveragePooling1D\u001b[0m)                                                                 \n",
              "\n",
              " lstm (\u001b[38;5;33mLSTM\u001b[0m)                           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                       \u001b[38;5;34m5,028,000\u001b[0m \n",
              "\n",
              " repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " Multi-Head (\u001b[38;5;33mMultiHeadAttention\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                    \u001b[38;5;34m4,004,000\u001b[0m \n",
              "\n",
              " lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                    \u001b[38;5;34m8,004,000\u001b[0m \n",
              "\n",
              " time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m40\u001b[0m)                         \u001b[38;5;34m40,040\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,976</span> \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " average_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> \n",
              "\n",
              " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " average_pooling1d_1                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)                                                                 \n",
              "\n",
              " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,028,000</span> \n",
              "\n",
              " repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " Multi-Head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">4,004,000</span> \n",
              "\n",
              " lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">8,004,000</span> \n",
              "\n",
              " time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">40,040</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,303,880\u001b[0m (66.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,303,880</span> (66.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,303,880\u001b[0m (66.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,303,880</span> (66.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 166ms/step - loss: 0.1217 - root_mean_squared_error: 0.3478 - val_loss: 0.1225 - val_root_mean_squared_error: 0.3501 - learning_rate: 0.0020\n",
            "Epoch 2/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 192ms/step - loss: 0.1039 - root_mean_squared_error: 0.3217 - val_loss: 0.1232 - val_root_mean_squared_error: 0.3510 - learning_rate: 0.0020\n",
            "Epoch 3/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - loss: 0.0822 - root_mean_squared_error: 0.2863 - val_loss: 0.0929 - val_root_mean_squared_error: 0.3048 - learning_rate: 0.0020\n",
            "Epoch 4/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0872 - root_mean_squared_error: 0.2952 - val_loss: 0.1575 - val_root_mean_squared_error: 0.3968 - learning_rate: 0.0020\n",
            "Epoch 5/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0844 - root_mean_squared_error: 0.2902 - val_loss: 0.1565 - val_root_mean_squared_error: 0.3955 - learning_rate: 0.0020\n",
            "Epoch 6/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0758 - root_mean_squared_error: 0.2751 - val_loss: 0.1508 - val_root_mean_squared_error: 0.3884 - learning_rate: 0.0020\n",
            "Epoch 7/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0728 - root_mean_squared_error: 0.2696 - val_loss: 0.1503 - val_root_mean_squared_error: 0.3876 - learning_rate: 0.0020\n",
            "Epoch 8/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 193ms/step - loss: 0.0738 - root_mean_squared_error: 0.2710 - val_loss: 0.1616 - val_root_mean_squared_error: 0.4020 - learning_rate: 0.0020\n",
            "Epoch 9/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0650 - root_mean_squared_error: 0.2541 - val_loss: 0.1580 - val_root_mean_squared_error: 0.3975 - learning_rate: 0.0020\n",
            "Epoch 10/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0694 - root_mean_squared_error: 0.2632 - val_loss: 0.1536 - val_root_mean_squared_error: 0.3919 - learning_rate: 0.0020\n",
            "Epoch 11/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - loss: 0.0519 - root_mean_squared_error: 0.2275 - val_loss: 0.1498 - val_root_mean_squared_error: 0.3871 - learning_rate: 0.0020\n",
            "Epoch 12/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0752 - root_mean_squared_error: 0.2735 - val_loss: 0.1379 - val_root_mean_squared_error: 0.3714 - learning_rate: 0.0020\n",
            "Epoch 13/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0658 - root_mean_squared_error: 0.2561 - val_loss: 0.1123 - val_root_mean_squared_error: 0.3351 - learning_rate: 0.0020\n",
            "Epoch 14/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0694 - root_mean_squared_error: 0.2627 - val_loss: 0.1146 - val_root_mean_squared_error: 0.3385 - learning_rate: 0.0020\n",
            "Epoch 15/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0581 - root_mean_squared_error: 0.2410 - val_loss: 0.1395 - val_root_mean_squared_error: 0.3735 - learning_rate: 0.0020\n",
            "Epoch 16/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0522 - root_mean_squared_error: 0.2285 - val_loss: 0.1146 - val_root_mean_squared_error: 0.3386 - learning_rate: 0.0020\n",
            "Epoch 17/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - loss: 0.0547 - root_mean_squared_error: 0.2334 - val_loss: 0.1111 - val_root_mean_squared_error: 0.3333 - learning_rate: 0.0020\n",
            "Epoch 18/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0435 - root_mean_squared_error: 0.2084 - val_loss: 0.1067 - val_root_mean_squared_error: 0.3267 - learning_rate: 0.0020\n",
            "Epoch 19/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.0536 - root_mean_squared_error: 0.2313 - val_loss: 0.0982 - val_root_mean_squared_error: 0.3134 - learning_rate: 0.0020\n",
            "Epoch 20/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0529 - root_mean_squared_error: 0.2295 - val_loss: 0.0959 - val_root_mean_squared_error: 0.3097 - learning_rate: 0.0020\n",
            "Epoch 21/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0472 - root_mean_squared_error: 0.2170 - val_loss: 0.0809 - val_root_mean_squared_error: 0.2843 - learning_rate: 0.0020\n",
            "Epoch 22/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0432 - root_mean_squared_error: 0.2077 - val_loss: 0.0795 - val_root_mean_squared_error: 0.2820 - learning_rate: 0.0020\n",
            "Epoch 23/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0446 - root_mean_squared_error: 0.2110 - val_loss: 0.0733 - val_root_mean_squared_error: 0.2708 - learning_rate: 0.0020\n",
            "Epoch 24/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0428 - root_mean_squared_error: 0.2069 - val_loss: 0.0795 - val_root_mean_squared_error: 0.2819 - learning_rate: 0.0020\n",
            "Epoch 25/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - loss: 0.0423 - root_mean_squared_error: 0.2056 - val_loss: 0.0729 - val_root_mean_squared_error: 0.2699 - learning_rate: 0.0020\n",
            "Epoch 26/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - loss: 0.0402 - root_mean_squared_error: 0.2005 - val_loss: 0.0751 - val_root_mean_squared_error: 0.2741 - learning_rate: 0.0020\n",
            "Epoch 27/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 320ms/step - loss: 0.0394 - root_mean_squared_error: 0.1985 - val_loss: 0.0730 - val_root_mean_squared_error: 0.2702 - learning_rate: 0.0020\n",
            "Epoch 28/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0389 - root_mean_squared_error: 0.1971 - val_loss: 0.0692 - val_root_mean_squared_error: 0.2630 - learning_rate: 0.0020\n",
            "Epoch 29/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0392 - root_mean_squared_error: 0.1979 - val_loss: 0.0725 - val_root_mean_squared_error: 0.2692 - learning_rate: 0.0020\n",
            "Epoch 30/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0395 - root_mean_squared_error: 0.1986 - val_loss: 0.0779 - val_root_mean_squared_error: 0.2791 - learning_rate: 0.0020\n",
            "Epoch 31/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0401 - root_mean_squared_error: 0.2002 - val_loss: 0.0776 - val_root_mean_squared_error: 0.2786 - learning_rate: 0.0020\n",
            "Epoch 32/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0390 - root_mean_squared_error: 0.1976 - val_loss: 0.0736 - val_root_mean_squared_error: 0.2714 - learning_rate: 0.0020\n",
            "Epoch 33/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0388 - root_mean_squared_error: 0.1969 - val_loss: 0.0728 - val_root_mean_squared_error: 0.2698 - learning_rate: 0.0020\n",
            "Epoch 34/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0386 - root_mean_squared_error: 0.1964 - val_loss: 0.0712 - val_root_mean_squared_error: 0.2669 - learning_rate: 0.0020\n",
            "Epoch 35/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0385 - root_mean_squared_error: 0.1961 - val_loss: 0.0824 - val_root_mean_squared_error: 0.2871 - learning_rate: 0.0020\n",
            "Epoch 36/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0384 - root_mean_squared_error: 0.1959 - val_loss: 0.0848 - val_root_mean_squared_error: 0.2912 - learning_rate: 0.0020\n",
            "Epoch 37/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0384 - root_mean_squared_error: 0.1959 - val_loss: 0.0817 - val_root_mean_squared_error: 0.2858 - learning_rate: 0.0020\n",
            "Epoch 38/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0387 - root_mean_squared_error: 0.1968 - val_loss: 0.0797 - val_root_mean_squared_error: 0.2823 - learning_rate: 0.0020\n",
            "Epoch 39/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0384 - root_mean_squared_error: 0.1961 - val_loss: 0.0817 - val_root_mean_squared_error: 0.2858 - learning_rate: 0.0020\n",
            "Epoch 40/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0384 - root_mean_squared_error: 0.1961 - val_loss: 0.0809 - val_root_mean_squared_error: 0.2845 - learning_rate: 0.0020\n",
            "Epoch 41/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 236ms/step - loss: 0.0385 - root_mean_squared_error: 0.1962 - val_loss: 0.0793 - val_root_mean_squared_error: 0.2816 - learning_rate: 0.0020\n",
            "Epoch 42/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0385 - root_mean_squared_error: 0.1962 - val_loss: 0.0782 - val_root_mean_squared_error: 0.2796 - learning_rate: 0.0020\n",
            "Epoch 43/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0384 - root_mean_squared_error: 0.1961 - val_loss: 0.0805 - val_root_mean_squared_error: 0.2838 - learning_rate: 0.0020\n",
            "Epoch 44/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.0384 - root_mean_squared_error: 0.1960 - val_loss: 0.0791 - val_root_mean_squared_error: 0.2812 - learning_rate: 0.0020\n",
            "Epoch 45/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 237ms/step - loss: 0.0382 - root_mean_squared_error: 0.1954 - val_loss: 0.0876 - val_root_mean_squared_error: 0.2959 - learning_rate: 0.0020\n",
            "Epoch 46/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0378 - root_mean_squared_error: 0.1945 - val_loss: 0.0776 - val_root_mean_squared_error: 0.2785 - learning_rate: 0.0020\n",
            "Epoch 47/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0381 - root_mean_squared_error: 0.1953 - val_loss: 0.0772 - val_root_mean_squared_error: 0.2779 - learning_rate: 0.0020\n",
            "Epoch 48/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0385 - root_mean_squared_error: 0.1962 - val_loss: 0.0716 - val_root_mean_squared_error: 0.2676 - learning_rate: 0.0020\n",
            "Epoch 49/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0392 - root_mean_squared_error: 0.1980 - val_loss: 0.0743 - val_root_mean_squared_error: 0.2726 - learning_rate: 0.0020\n",
            "Epoch 50/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0394 - root_mean_squared_error: 0.1985 - val_loss: 0.0818 - val_root_mean_squared_error: 0.2861 - learning_rate: 0.0020\n",
            "Epoch 51/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0395 - root_mean_squared_error: 0.1986 - val_loss: 0.0872 - val_root_mean_squared_error: 0.2952 - learning_rate: 0.0020\n",
            "Epoch 52/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0388 - root_mean_squared_error: 0.1969 - val_loss: 0.0745 - val_root_mean_squared_error: 0.2730 - learning_rate: 0.0020\n",
            "Epoch 53/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0385 - root_mean_squared_error: 0.1963 - val_loss: 0.0811 - val_root_mean_squared_error: 0.2847 - learning_rate: 0.0020\n",
            "Epoch 54/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0387 - root_mean_squared_error: 0.1968 - val_loss: 0.0662 - val_root_mean_squared_error: 0.2573 - learning_rate: 0.0020\n",
            "Epoch 55/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.0397 - root_mean_squared_error: 0.1991 - val_loss: 0.0813 - val_root_mean_squared_error: 0.2851 - learning_rate: 0.0020\n",
            "Epoch 56/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0393 - root_mean_squared_error: 0.1982 - val_loss: 0.0739 - val_root_mean_squared_error: 0.2718 - learning_rate: 0.0020\n",
            "Epoch 57/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0397 - root_mean_squared_error: 0.1991 - val_loss: 0.0702 - val_root_mean_squared_error: 0.2650 - learning_rate: 0.0020\n",
            "Epoch 58/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0394 - root_mean_squared_error: 0.1985 - val_loss: 0.0701 - val_root_mean_squared_error: 0.2647 - learning_rate: 0.0020\n",
            "Epoch 59/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0394 - root_mean_squared_error: 0.1984 - val_loss: 0.0726 - val_root_mean_squared_error: 0.2695 - learning_rate: 0.0020\n",
            "Epoch 60/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0412 - root_mean_squared_error: 0.2028 - val_loss: 0.0835 - val_root_mean_squared_error: 0.2890 - learning_rate: 0.0020\n",
            "Epoch 61/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0414 - root_mean_squared_error: 0.2033 - val_loss: 0.0679 - val_root_mean_squared_error: 0.2606 - learning_rate: 0.0020\n",
            "Epoch 62/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0505 - root_mean_squared_error: 0.2244 - val_loss: 0.0755 - val_root_mean_squared_error: 0.2747 - learning_rate: 0.0020\n",
            "Epoch 63/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0753 - root_mean_squared_error: 0.2728 - val_loss: 0.0852 - val_root_mean_squared_error: 0.2918 - learning_rate: 0.0020\n",
            "Epoch 64/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0769 - root_mean_squared_error: 0.2769 - val_loss: 0.0950 - val_root_mean_squared_error: 0.3083 - learning_rate: 0.0020\n",
            "Epoch 65/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0517 - root_mean_squared_error: 0.2271 - val_loss: 0.0862 - val_root_mean_squared_error: 0.2937 - learning_rate: 0.0020\n",
            "Epoch 66/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0421 - root_mean_squared_error: 0.2052 - val_loss: 0.0705 - val_root_mean_squared_error: 0.2655 - learning_rate: 0.0020\n",
            "Epoch 67/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0440 - root_mean_squared_error: 0.2096 - val_loss: 0.0586 - val_root_mean_squared_error: 0.2422 - learning_rate: 0.0020\n",
            "Epoch 68/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0441 - root_mean_squared_error: 0.2095 - val_loss: 0.0618 - val_root_mean_squared_error: 0.2485 - learning_rate: 0.0020\n",
            "Epoch 69/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0468 - root_mean_squared_error: 0.2157 - val_loss: 0.0640 - val_root_mean_squared_error: 0.2530 - learning_rate: 0.0020\n",
            "Epoch 70/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0452 - root_mean_squared_error: 0.2122 - val_loss: 0.0715 - val_root_mean_squared_error: 0.2674 - learning_rate: 0.0020\n",
            "Epoch 71/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0419 - root_mean_squared_error: 0.2046 - val_loss: 0.0695 - val_root_mean_squared_error: 0.2635 - learning_rate: 0.0020\n",
            "Epoch 72/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0455 - root_mean_squared_error: 0.2129 - val_loss: 0.0787 - val_root_mean_squared_error: 0.2806 - learning_rate: 0.0020\n",
            "Epoch 73/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0399 - root_mean_squared_error: 0.1997 - val_loss: 0.0696 - val_root_mean_squared_error: 0.2638 - learning_rate: 0.0020\n",
            "Epoch 74/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0400 - root_mean_squared_error: 0.1999 - val_loss: 0.0658 - val_root_mean_squared_error: 0.2566 - learning_rate: 0.0020\n",
            "Epoch 75/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0421 - root_mean_squared_error: 0.2052 - val_loss: 0.0645 - val_root_mean_squared_error: 0.2540 - learning_rate: 0.0020\n",
            "Epoch 76/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0389 - root_mean_squared_error: 0.1973 - val_loss: 0.0627 - val_root_mean_squared_error: 0.2505 - learning_rate: 0.0020\n",
            "Epoch 77/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0395 - root_mean_squared_error: 0.1988 - val_loss: 0.0620 - val_root_mean_squared_error: 0.2490 - learning_rate: 0.0020\n",
            "Epoch 78/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0387 - root_mean_squared_error: 0.1968 - val_loss: 0.0613 - val_root_mean_squared_error: 0.2475 - learning_rate: 0.0020\n",
            "Epoch 79/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0386 - root_mean_squared_error: 0.1965 - val_loss: 0.0624 - val_root_mean_squared_error: 0.2499 - learning_rate: 0.0020\n",
            "Epoch 80/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0395 - root_mean_squared_error: 0.1987 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2467 - learning_rate: 0.0020\n",
            "Epoch 81/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0384 - root_mean_squared_error: 0.1960 - val_loss: 0.0619 - val_root_mean_squared_error: 0.2489 - learning_rate: 0.0020\n",
            "Epoch 82/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0381 - root_mean_squared_error: 0.1951 - val_loss: 0.0606 - val_root_mean_squared_error: 0.2461 - learning_rate: 0.0020\n",
            "Epoch 83/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0608 - val_root_mean_squared_error: 0.2467 - learning_rate: 0.0020\n",
            "Epoch 84/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0380 - root_mean_squared_error: 0.1950 - val_loss: 0.0604 - val_root_mean_squared_error: 0.2457 - learning_rate: 0.0020\n",
            "Epoch 85/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0394 - root_mean_squared_error: 0.1984 - val_loss: 0.0611 - val_root_mean_squared_error: 0.2471 - learning_rate: 0.0020\n",
            "Epoch 86/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0384 - root_mean_squared_error: 0.1959 - val_loss: 0.0613 - val_root_mean_squared_error: 0.2475 - learning_rate: 0.0020\n",
            "Epoch 87/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0384 - root_mean_squared_error: 0.1959 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2469 - learning_rate: 0.0020\n",
            "Epoch 88/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0383 - root_mean_squared_error: 0.1956 - val_loss: 0.0607 - val_root_mean_squared_error: 0.2465 - learning_rate: 0.0020\n",
            "Epoch 89/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0384 - root_mean_squared_error: 0.1959 - val_loss: 0.0608 - val_root_mean_squared_error: 0.2465 - learning_rate: 0.0020\n",
            "Epoch 90/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0379 - root_mean_squared_error: 0.1947 - val_loss: 0.0604 - val_root_mean_squared_error: 0.2457 - learning_rate: 0.0020\n",
            "Epoch 91/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0376 - root_mean_squared_error: 0.1940 - val_loss: 0.0603 - val_root_mean_squared_error: 0.2455 - learning_rate: 0.0020\n",
            "Epoch 92/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 170ms/step - loss: 0.0374 - root_mean_squared_error: 0.1935 - val_loss: 0.0601 - val_root_mean_squared_error: 0.2451 - learning_rate: 0.0020\n",
            "Epoch 93/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - loss: 0.0375 - root_mean_squared_error: 0.1937 - val_loss: 0.0603 - val_root_mean_squared_error: 0.2455 - learning_rate: 0.0020\n",
            "Epoch 94/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 182ms/step - loss: 0.0373 - root_mean_squared_error: 0.1930 - val_loss: 0.0604 - val_root_mean_squared_error: 0.2458 - learning_rate: 0.0020\n",
            "Epoch 95/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.0378 - root_mean_squared_error: 0.1945 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2445 - learning_rate: 0.0020\n",
            "Epoch 96/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0375 - root_mean_squared_error: 0.1936 - val_loss: 0.0588 - val_root_mean_squared_error: 0.2426 - learning_rate: 0.0020\n",
            "Epoch 97/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0376 - root_mean_squared_error: 0.1938 - val_loss: 0.0589 - val_root_mean_squared_error: 0.2427 - learning_rate: 0.0020\n",
            "Epoch 98/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0375 - root_mean_squared_error: 0.1937 - val_loss: 0.0597 - val_root_mean_squared_error: 0.2443 - learning_rate: 0.0020\n",
            "Epoch 99/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0381 - root_mean_squared_error: 0.1952 - val_loss: 0.0595 - val_root_mean_squared_error: 0.2439 - learning_rate: 0.0020\n",
            "Epoch 100/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0383 - root_mean_squared_error: 0.1958 - val_loss: 0.0599 - val_root_mean_squared_error: 0.2447 - learning_rate: 0.0020\n",
            "Epoch 101/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0380 - root_mean_squared_error: 0.1949 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2481 - learning_rate: 0.0020\n",
            "Epoch 102/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0380 - root_mean_squared_error: 0.1948 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2446 - learning_rate: 0.0020\n",
            "Epoch 103/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - loss: 0.0372 - root_mean_squared_error: 0.1928 - val_loss: 0.0607 - val_root_mean_squared_error: 0.2465 - learning_rate: 0.0020\n",
            "Epoch 104/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - loss: 0.0372 - root_mean_squared_error: 0.1930 - val_loss: 0.0601 - val_root_mean_squared_error: 0.2452 - learning_rate: 0.0020\n",
            "Epoch 105/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0370 - root_mean_squared_error: 0.1923 - val_loss: 0.0605 - val_root_mean_squared_error: 0.2460 - learning_rate: 0.0020\n",
            "Epoch 106/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0370 - root_mean_squared_error: 0.1924 - val_loss: 0.0593 - val_root_mean_squared_error: 0.2434 - learning_rate: 0.0020\n",
            "Epoch 107/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0368 - root_mean_squared_error: 0.1919 - val_loss: 0.0608 - val_root_mean_squared_error: 0.2465 - learning_rate: 0.0020\n",
            "Epoch 108/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0369 - root_mean_squared_error: 0.1921 - val_loss: 0.0601 - val_root_mean_squared_error: 0.2452 - learning_rate: 0.0020\n",
            "Epoch 109/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - loss: 0.0367 - root_mean_squared_error: 0.1916 - val_loss: 0.0606 - val_root_mean_squared_error: 0.2461 - learning_rate: 0.0020\n",
            "Epoch 110/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0369 - root_mean_squared_error: 0.1921 - val_loss: 0.0603 - val_root_mean_squared_error: 0.2455 - learning_rate: 0.0020\n",
            "Epoch 111/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0366 - root_mean_squared_error: 0.1913 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2468 - learning_rate: 0.0020\n",
            "Epoch 112/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0370 - root_mean_squared_error: 0.1923 - val_loss: 0.0602 - val_root_mean_squared_error: 0.2454 - learning_rate: 0.0020\n",
            "Epoch 113/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0367 - root_mean_squared_error: 0.1916 - val_loss: 0.0611 - val_root_mean_squared_error: 0.2472 - learning_rate: 0.0020\n",
            "Epoch 114/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0369 - root_mean_squared_error: 0.1920 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2445 - learning_rate: 0.0020\n",
            "Epoch 115/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0366 - root_mean_squared_error: 0.1913 - val_loss: 0.0605 - val_root_mean_squared_error: 0.2460 - learning_rate: 0.0020\n",
            "Epoch 116/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0375 - root_mean_squared_error: 0.1937 - val_loss: 0.0596 - val_root_mean_squared_error: 0.2441 - learning_rate: 0.0020\n",
            "Epoch 117/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0369 - root_mean_squared_error: 0.1921 - val_loss: 0.0606 - val_root_mean_squared_error: 0.2462 - learning_rate: 0.0020\n",
            "Epoch 118/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0372 - root_mean_squared_error: 0.1928 - val_loss: 0.0592 - val_root_mean_squared_error: 0.2433 - learning_rate: 0.0020\n",
            "Epoch 119/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0369 - root_mean_squared_error: 0.1921 - val_loss: 0.0603 - val_root_mean_squared_error: 0.2456 - learning_rate: 0.0020\n",
            "Epoch 120/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0368 - root_mean_squared_error: 0.1917 - val_loss: 0.0591 - val_root_mean_squared_error: 0.2430 - learning_rate: 0.0020\n",
            "Epoch 121/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0366 - root_mean_squared_error: 0.1913 - val_loss: 0.0607 - val_root_mean_squared_error: 0.2463 - learning_rate: 0.0020\n",
            "Epoch 122/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0367 - root_mean_squared_error: 0.1915 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2428 - learning_rate: 0.0020\n",
            "Epoch 123/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0368 - root_mean_squared_error: 0.1917 - val_loss: 0.0758 - val_root_mean_squared_error: 0.2753 - learning_rate: 0.0020\n",
            "Epoch 124/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0373 - root_mean_squared_error: 0.1930 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2400 - learning_rate: 0.0020\n",
            "Epoch 125/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0368 - root_mean_squared_error: 0.1918 - val_loss: 0.0629 - val_root_mean_squared_error: 0.2509 - learning_rate: 0.0020\n",
            "Epoch 126/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0368 - root_mean_squared_error: 0.1918 - val_loss: 0.0606 - val_root_mean_squared_error: 0.2463 - learning_rate: 0.0020\n",
            "Epoch 127/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0365 - root_mean_squared_error: 0.1912 - val_loss: 0.0613 - val_root_mean_squared_error: 0.2475 - learning_rate: 0.0020\n",
            "Epoch 128/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0363 - root_mean_squared_error: 0.1906 - val_loss: 0.0620 - val_root_mean_squared_error: 0.2489 - learning_rate: 0.0020\n",
            "Epoch 129/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 246ms/step - loss: 0.0364 - root_mean_squared_error: 0.1907 - val_loss: 0.0606 - val_root_mean_squared_error: 0.2461 - learning_rate: 0.0020\n",
            "Epoch 130/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0362 - root_mean_squared_error: 0.1902 - val_loss: 0.0615 - val_root_mean_squared_error: 0.2480 - learning_rate: 0.0020\n",
            "Epoch 131/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 228ms/step - loss: 0.0362 - root_mean_squared_error: 0.1903 - val_loss: 0.0604 - val_root_mean_squared_error: 0.2457 - learning_rate: 0.0020\n",
            "Epoch 132/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0360 - root_mean_squared_error: 0.1898 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2482 - learning_rate: 0.0020\n",
            "Epoch 133/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0359 - root_mean_squared_error: 0.1895 - val_loss: 0.0601 - val_root_mean_squared_error: 0.2451 - learning_rate: 0.0020\n",
            "Epoch 134/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 228ms/step - loss: 0.0359 - root_mean_squared_error: 0.1894 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2482 - learning_rate: 0.0020\n",
            "Epoch 135/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0366 - root_mean_squared_error: 0.1914 - val_loss: 0.0605 - val_root_mean_squared_error: 0.2461 - learning_rate: 0.0020\n",
            "Epoch 136/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0370 - root_mean_squared_error: 0.1923 - val_loss: 0.0611 - val_root_mean_squared_error: 0.2472 - learning_rate: 0.0020\n",
            "Epoch 137/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0369 - root_mean_squared_error: 0.1921 - val_loss: 0.0615 - val_root_mean_squared_error: 0.2480 - learning_rate: 0.0020\n",
            "Epoch 138/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0378 - root_mean_squared_error: 0.1944 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2467 - learning_rate: 0.0020\n",
            "Epoch 139/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0375 - root_mean_squared_error: 0.1937 - val_loss: 0.0608 - val_root_mean_squared_error: 0.2466 - learning_rate: 0.0020\n",
            "Epoch 140/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0383 - root_mean_squared_error: 0.1957 - val_loss: 0.0599 - val_root_mean_squared_error: 0.2447 - learning_rate: 0.0020\n",
            "Epoch 141/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0373 - root_mean_squared_error: 0.1931 - val_loss: 0.0617 - val_root_mean_squared_error: 0.2484 - learning_rate: 0.0020\n",
            "Epoch 142/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0377 - root_mean_squared_error: 0.1940 - val_loss: 0.0589 - val_root_mean_squared_error: 0.2427 - learning_rate: 0.0020\n",
            "Epoch 143/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0370 - root_mean_squared_error: 0.1924 - val_loss: 0.0607 - val_root_mean_squared_error: 0.2463 - learning_rate: 0.0020\n",
            "Epoch 144/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0370 - root_mean_squared_error: 0.1922 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2411 - learning_rate: 0.0020\n",
            "Epoch 145/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0363 - root_mean_squared_error: 0.1905 - val_loss: 0.0606 - val_root_mean_squared_error: 0.2461 - learning_rate: 0.0020\n",
            "Epoch 146/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0364 - root_mean_squared_error: 0.1908 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2429 - learning_rate: 0.0020\n",
            "Epoch 147/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0365 - root_mean_squared_error: 0.1910 - val_loss: 0.0599 - val_root_mean_squared_error: 0.2447 - learning_rate: 0.0020\n",
            "Epoch 148/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0372 - root_mean_squared_error: 0.1928 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2445 - learning_rate: 0.0020\n",
            "Epoch 149/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0375 - root_mean_squared_error: 0.1937 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2446 - learning_rate: 0.0020\n",
            "Epoch 150/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0373 - root_mean_squared_error: 0.1932 - val_loss: 0.0608 - val_root_mean_squared_error: 0.2467 - learning_rate: 0.0020\n",
            "Epoch 151/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0370 - root_mean_squared_error: 0.1924 - val_loss: 0.0589 - val_root_mean_squared_error: 0.2427 - learning_rate: 0.0020\n",
            "Epoch 152/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0374 - root_mean_squared_error: 0.1932 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2468 - learning_rate: 0.0020\n",
            "Epoch 153/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0362 - root_mean_squared_error: 0.1903 - val_loss: 0.0584 - val_root_mean_squared_error: 0.2417 - learning_rate: 0.0020\n",
            "Epoch 154/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0363 - root_mean_squared_error: 0.1905 - val_loss: 0.0599 - val_root_mean_squared_error: 0.2446 - learning_rate: 0.0020\n",
            "Epoch 155/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0358 - root_mean_squared_error: 0.1891 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2400 - learning_rate: 0.0020\n",
            "Epoch 156/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0358 - root_mean_squared_error: 0.1891 - val_loss: 0.0587 - val_root_mean_squared_error: 0.2423 - learning_rate: 0.0020\n",
            "Epoch 157/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0361 - root_mean_squared_error: 0.1901 - val_loss: 0.0588 - val_root_mean_squared_error: 0.2424 - learning_rate: 0.0020\n",
            "Epoch 158/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0358 - root_mean_squared_error: 0.1893 - val_loss: 0.0586 - val_root_mean_squared_error: 0.2422 - learning_rate: 0.0020\n",
            "Epoch 159/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0360 - root_mean_squared_error: 0.1897 - val_loss: 0.0569 - val_root_mean_squared_error: 0.2386 - learning_rate: 0.0020\n",
            "Epoch 160/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0363 - root_mean_squared_error: 0.1903 - val_loss: 0.0604 - val_root_mean_squared_error: 0.2457 - learning_rate: 0.0020\n",
            "Epoch 161/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0361 - root_mean_squared_error: 0.1898 - val_loss: 0.0572 - val_root_mean_squared_error: 0.2392 - learning_rate: 0.0020\n",
            "Epoch 162/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0357 - root_mean_squared_error: 0.1889 - val_loss: 0.0602 - val_root_mean_squared_error: 0.2454 - learning_rate: 0.0020\n",
            "Epoch 163/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - loss: 0.0355 - root_mean_squared_error: 0.1882 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2400 - learning_rate: 0.0020\n",
            "Epoch 164/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 0.0351 - root_mean_squared_error: 0.1872 - val_loss: 0.0597 - val_root_mean_squared_error: 0.2442 - learning_rate: 0.0020\n",
            "Epoch 165/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0350 - root_mean_squared_error: 0.1869 - val_loss: 0.0589 - val_root_mean_squared_error: 0.2428 - learning_rate: 0.0020\n",
            "Epoch 166/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0349 - root_mean_squared_error: 0.1866 - val_loss: 0.0584 - val_root_mean_squared_error: 0.2417 - learning_rate: 0.0020\n",
            "Epoch 167/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 165ms/step - loss: 0.0346 - root_mean_squared_error: 0.1859 - val_loss: 0.0585 - val_root_mean_squared_error: 0.2420 - learning_rate: 0.0020\n",
            "Epoch 168/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0348 - root_mean_squared_error: 0.1863 - val_loss: 0.0579 - val_root_mean_squared_error: 0.2405 - learning_rate: 0.0020\n",
            "Epoch 169/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0350 - root_mean_squared_error: 0.1869 - val_loss: 0.0578 - val_root_mean_squared_error: 0.2403 - learning_rate: 0.0020\n",
            "Epoch 170/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0348 - root_mean_squared_error: 0.1865 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2410 - learning_rate: 0.0020\n",
            "Epoch 171/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0350 - root_mean_squared_error: 0.1869 - val_loss: 0.0577 - val_root_mean_squared_error: 0.2402 - learning_rate: 0.0020\n",
            "Epoch 172/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0345 - root_mean_squared_error: 0.1856 - val_loss: 0.0595 - val_root_mean_squared_error: 0.2440 - learning_rate: 0.0020\n",
            "Epoch 173/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0346 - root_mean_squared_error: 0.1857 - val_loss: 0.0580 - val_root_mean_squared_error: 0.2408 - learning_rate: 0.0020\n",
            "Epoch 174/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2445 - learning_rate: 0.0020\n",
            "Epoch 175/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0344 - root_mean_squared_error: 0.1852 - val_loss: 0.0575 - val_root_mean_squared_error: 0.2398 - learning_rate: 0.0020\n",
            "Epoch 176/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.0341 - root_mean_squared_error: 0.1844 - val_loss: 0.0601 - val_root_mean_squared_error: 0.2452 - learning_rate: 0.0020\n",
            "Epoch 177/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0347 - root_mean_squared_error: 0.1862 - val_loss: 0.0575 - val_root_mean_squared_error: 0.2397 - learning_rate: 0.0020\n",
            "Epoch 178/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0604 - val_root_mean_squared_error: 0.2457 - learning_rate: 0.0020\n",
            "Epoch 179/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0346 - root_mean_squared_error: 0.1860 - val_loss: 0.0580 - val_root_mean_squared_error: 0.2409 - learning_rate: 0.0020\n",
            "Epoch 180/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0605 - val_root_mean_squared_error: 0.2459 - learning_rate: 0.0020\n",
            "Epoch 181/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0614 - val_root_mean_squared_error: 0.2479 - learning_rate: 0.0020\n",
            "Epoch 182/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0342 - root_mean_squared_error: 0.1847 - val_loss: 0.0583 - val_root_mean_squared_error: 0.2414 - learning_rate: 0.0020\n",
            "Epoch 183/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0600 - val_root_mean_squared_error: 0.2449 - learning_rate: 0.0020\n",
            "Epoch 184/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0340 - root_mean_squared_error: 0.1842 - val_loss: 0.0595 - val_root_mean_squared_error: 0.2439 - learning_rate: 0.0020\n",
            "Epoch 185/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 289ms/step - loss: 0.0340 - root_mean_squared_error: 0.1841 - val_loss: 0.0611 - val_root_mean_squared_error: 0.2472 - learning_rate: 0.0020\n",
            "Epoch 186/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - loss: 0.0338 - root_mean_squared_error: 0.1836 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2401 - learning_rate: 0.0020\n",
            "Epoch 187/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0339 - root_mean_squared_error: 0.1838 - val_loss: 0.0597 - val_root_mean_squared_error: 0.2444 - learning_rate: 0.0020\n",
            "Epoch 188/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0339 - root_mean_squared_error: 0.1840 - val_loss: 0.0591 - val_root_mean_squared_error: 0.2431 - learning_rate: 0.0020\n",
            "Epoch 189/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0341 - root_mean_squared_error: 0.1844 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2430 - learning_rate: 0.0020\n",
            "Epoch 190/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0338 - root_mean_squared_error: 0.1838 - val_loss: 0.0603 - val_root_mean_squared_error: 0.2455 - learning_rate: 0.0020\n",
            "Epoch 191/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0338 - root_mean_squared_error: 0.1836 - val_loss: 0.0586 - val_root_mean_squared_error: 0.2421 - learning_rate: 0.0020\n",
            "Epoch 192/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.0339 - root_mean_squared_error: 0.1840 - val_loss: 0.0610 - val_root_mean_squared_error: 0.2470 - learning_rate: 0.0020\n",
            "Epoch 193/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0344 - root_mean_squared_error: 0.1852 - val_loss: 0.0593 - val_root_mean_squared_error: 0.2435 - learning_rate: 0.0020\n",
            "Epoch 194/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0347 - root_mean_squared_error: 0.1861 - val_loss: 0.0612 - val_root_mean_squared_error: 0.2474 - learning_rate: 0.0020\n",
            "Epoch 195/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0346 - root_mean_squared_error: 0.1858 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2481 - learning_rate: 0.0020\n",
            "Epoch 196/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0344 - root_mean_squared_error: 0.1852 - val_loss: 0.0604 - val_root_mean_squared_error: 0.2457 - learning_rate: 0.0020\n",
            "Epoch 197/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0345 - root_mean_squared_error: 0.1856 - val_loss: 0.0630 - val_root_mean_squared_error: 0.2509 - learning_rate: 0.0020\n",
            "Epoch 198/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0346 - root_mean_squared_error: 0.1859 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2446 - learning_rate: 0.0020\n",
            "Epoch 199/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0348 - root_mean_squared_error: 0.1863 - val_loss: 0.0619 - val_root_mean_squared_error: 0.2487 - learning_rate: 0.0020\n",
            "Epoch 200/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0351 - root_mean_squared_error: 0.1872 - val_loss: 0.0610 - val_root_mean_squared_error: 0.2470 - learning_rate: 0.0020\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Open          High           Low         Close     Adj Close  \\\n",
            "0    1.978147e-07  1.994812e-07  1.982015e-07  1.985642e-07  1.989476e-07   \n",
            "1    1.978147e-07  1.994812e-07  1.982015e-07  1.985642e-07  1.989476e-07   \n",
            "2    1.978147e-07  1.994812e-07  1.982015e-07  1.985642e-07  1.989476e-07   \n",
            "3    1.978147e-07  1.994812e-07  1.982015e-07  1.985642e-07  1.989476e-07   \n",
            "4    1.978147e-07  1.994812e-07  1.982015e-07  1.985642e-07  1.989476e-07   \n",
            "..            ...           ...           ...           ...           ...   \n",
            "115  1.978147e-07  1.994812e-07  1.982015e-07  1.985642e-07  1.989476e-07   \n",
            "116  1.978147e-07  1.994812e-07  1.982015e-07  1.985642e-07  1.989476e-07   \n",
            "117  1.978147e-07  1.994812e-07  1.982015e-07  1.985642e-07  1.989476e-07   \n",
            "118  1.978147e-07  1.994812e-07  1.982015e-07  1.985642e-07  1.989476e-07   \n",
            "119  1.978147e-07  1.994812e-07  1.982015e-07  1.985642e-07  1.989476e-07   \n",
            "\n",
            "       Volume         0         1         2         0  ...        21  \\\n",
            "0    2.034066  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031   \n",
            "1    2.034066  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031   \n",
            "2    2.034066  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031   \n",
            "3    2.034066  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031   \n",
            "4    2.034066  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031   \n",
            "..        ...       ...       ...       ...       ...  ...       ...   \n",
            "115  2.034066  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031   \n",
            "116  2.034066  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031   \n",
            "117  2.034066  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031   \n",
            "118  2.034066  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031   \n",
            "119  2.034066  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031   \n",
            "\n",
            "           22        23        24        25        26        27        28  \\\n",
            "0    0.010108  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507   \n",
            "1    0.010108  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507   \n",
            "2    0.010108  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507   \n",
            "3    0.010108  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507   \n",
            "4    0.010108  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "115  0.010108  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507   \n",
            "116  0.010108  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507   \n",
            "117  0.010108  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507   \n",
            "118  0.010108  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507   \n",
            "119  0.010108  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507   \n",
            "\n",
            "           29        30  \n",
            "0    0.000021 -0.017907  \n",
            "1    0.000021 -0.017907  \n",
            "2    0.000021 -0.017907  \n",
            "3    0.000021 -0.017907  \n",
            "4    0.000021 -0.017907  \n",
            "..        ...       ...  \n",
            "115  0.000021 -0.017907  \n",
            "116  0.000021 -0.017907  \n",
            "117  0.000021 -0.017907  \n",
            "118  0.000021 -0.017907  \n",
            "119  0.000021 -0.017907  \n",
            "\n",
            "[120 rows x 40 columns]\n",
            "           Actual     Predicted\n",
            "0    3.052210e-07  1.989476e-07\n",
            "1    3.034849e-07  1.989476e-07\n",
            "2    3.009333e-07  1.989476e-07\n",
            "3    3.005540e-07  1.989476e-07\n",
            "4    2.962310e-07  1.989476e-07\n",
            "..            ...           ...\n",
            "115  2.970656e-07  1.989476e-07\n",
            "116  2.950631e-07  1.989476e-07\n",
            "117  2.986630e-07  1.989476e-07\n",
            "118  2.983086e-07  1.989476e-07\n",
            "119  2.954335e-07  1.989476e-07\n",
            "\n",
            "[120 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'XEN-USD': (2.954335e-07, 1.989475957860883e-07)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2acd743933a4>:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:201: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:201: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:201: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:201: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:201: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:201: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_1              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m)                       \u001b[38;5;34m0\u001b[0m  -                      \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                                              \n",
              "\n",
              " lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)              [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,        \u001b[38;5;34m9,246,000\u001b[0m  input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "                            \u001b[38;5;34m1500\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m)]                                           \n",
              "\n",
              " repeat_vector_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1500\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
              " (\u001b[38;5;33mRepeatVector\u001b[0m)                                                                            \n",
              "\n",
              " multi_head_attention       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1500\u001b[0m)              \u001b[38;5;34m9,006,000\u001b[0m  repeat_vector_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mMultiHeadAttention\u001b[0m)                                                                      \n",
              "\n",
              " lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1500\u001b[0m)             \u001b[38;5;34m18,006,000\u001b[0m  multi_head_attention[\u001b[38;5;34m\u001b[0m \n",
              "                                                                    lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],          \n",
              "                                                                    lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]           \n",
              "\n",
              " time_distributed_1         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m40\u001b[0m)                   \u001b[38;5;34m60,040\u001b[0m  lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
              " (\u001b[38;5;33mTimeDistributed\u001b[0m)                                                                         \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)              </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">        Param # </span><span style=\"font-weight: bold\"> Connected to           </span>\n",
              "\n",
              " input_layer_1              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                                              \n",
              "\n",
              " lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">9,246,000</span>  input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "                            <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)]                                           \n",
              "\n",
              " repeat_vector_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)                                                                            \n",
              "\n",
              " multi_head_attention       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">9,006,000</span>  repeat_vector_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)                                                                      \n",
              "\n",
              " lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">18,006,000</span>  multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                                    lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],          \n",
              "                                                                    lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]           \n",
              "\n",
              " time_distributed_1         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">60,040</span>  lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                                                                         \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,318,040\u001b[0m (138.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,318,040</span> (138.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,318,040\u001b[0m (138.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,318,040</span> (138.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - loss: 0.0510 - root_mean_squared_error: 0.2259 - val_loss: 0.0506 - val_root_mean_squared_error: 0.2250\n",
            "Epoch 2/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0458 - root_mean_squared_error: 0.2140 - val_loss: 0.0517 - val_root_mean_squared_error: 0.2274\n",
            "Epoch 3/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0415 - root_mean_squared_error: 0.2036 - val_loss: 0.0533 - val_root_mean_squared_error: 0.2309\n",
            "Epoch 4/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0388 - root_mean_squared_error: 0.1969 - val_loss: 0.0543 - val_root_mean_squared_error: 0.2330\n",
            "Epoch 5/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0371 - root_mean_squared_error: 0.1925 - val_loss: 0.0541 - val_root_mean_squared_error: 0.2325\n",
            "Epoch 6/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0364 - root_mean_squared_error: 0.1908 - val_loss: 0.0530 - val_root_mean_squared_error: 0.2302\n",
            "Epoch 7/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0356 - root_mean_squared_error: 0.1886 - val_loss: 0.0515 - val_root_mean_squared_error: 0.2269\n",
            "Epoch 8/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0351 - root_mean_squared_error: 0.1872 - val_loss: 0.0498 - val_root_mean_squared_error: 0.2230\n",
            "Epoch 9/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0349 - root_mean_squared_error: 0.1868 - val_loss: 0.0483 - val_root_mean_squared_error: 0.2197\n",
            "Epoch 10/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0337 - root_mean_squared_error: 0.1835 - val_loss: 0.0470 - val_root_mean_squared_error: 0.2169\n",
            "Epoch 11/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0335 - root_mean_squared_error: 0.1831 - val_loss: 0.0463 - val_root_mean_squared_error: 0.2151\n",
            "Epoch 12/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0339 - root_mean_squared_error: 0.1841 - val_loss: 0.0460 - val_root_mean_squared_error: 0.2144\n",
            "Epoch 13/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0330 - root_mean_squared_error: 0.1816 - val_loss: 0.0460 - val_root_mean_squared_error: 0.2144\n",
            "Epoch 14/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0338 - root_mean_squared_error: 0.1838 - val_loss: 0.0461 - val_root_mean_squared_error: 0.2146\n",
            "Epoch 15/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0334 - root_mean_squared_error: 0.1826 - val_loss: 0.0464 - val_root_mean_squared_error: 0.2153\n",
            "Epoch 16/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0325 - root_mean_squared_error: 0.1804 - val_loss: 0.0467 - val_root_mean_squared_error: 0.2162\n",
            "Epoch 17/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0333 - root_mean_squared_error: 0.1825 - val_loss: 0.0470 - val_root_mean_squared_error: 0.2169\n",
            "Epoch 18/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0326 - root_mean_squared_error: 0.1806 - val_loss: 0.0473 - val_root_mean_squared_error: 0.2174\n",
            "Epoch 19/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0333 - root_mean_squared_error: 0.1825 - val_loss: 0.0474 - val_root_mean_squared_error: 0.2176\n",
            "Epoch 20/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0322 - root_mean_squared_error: 0.1794 - val_loss: 0.0477 - val_root_mean_squared_error: 0.2183\n",
            "Epoch 21/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0329 - root_mean_squared_error: 0.1815 - val_loss: 0.0481 - val_root_mean_squared_error: 0.2194\n",
            "Epoch 22/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0323 - root_mean_squared_error: 0.1796 - val_loss: 0.0486 - val_root_mean_squared_error: 0.2204\n",
            "Epoch 23/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0317 - root_mean_squared_error: 0.1779 - val_loss: 0.0490 - val_root_mean_squared_error: 0.2214\n",
            "Epoch 24/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0329 - root_mean_squared_error: 0.1814 - val_loss: 0.0492 - val_root_mean_squared_error: 0.2219\n",
            "Epoch 25/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0324 - root_mean_squared_error: 0.1800 - val_loss: 0.0484 - val_root_mean_squared_error: 0.2199\n",
            "Epoch 26/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0321 - root_mean_squared_error: 0.1791 - val_loss: 0.0481 - val_root_mean_squared_error: 0.2194\n",
            "Epoch 27/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0308 - root_mean_squared_error: 0.1756 - val_loss: 0.0482 - val_root_mean_squared_error: 0.2195\n",
            "Epoch 28/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0311 - root_mean_squared_error: 0.1763 - val_loss: 0.0486 - val_root_mean_squared_error: 0.2204\n",
            "Epoch 29/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0307 - root_mean_squared_error: 0.1753 - val_loss: 0.0491 - val_root_mean_squared_error: 0.2216\n",
            "Epoch 30/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0307 - root_mean_squared_error: 0.1751 - val_loss: 0.0495 - val_root_mean_squared_error: 0.2225\n",
            "Epoch 31/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0303 - root_mean_squared_error: 0.1741 - val_loss: 0.0499 - val_root_mean_squared_error: 0.2234\n",
            "Epoch 32/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0295 - root_mean_squared_error: 0.1716 - val_loss: 0.0502 - val_root_mean_squared_error: 0.2241\n",
            "Epoch 33/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0293 - root_mean_squared_error: 0.1713 - val_loss: 0.0505 - val_root_mean_squared_error: 0.2248\n",
            "Epoch 34/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0292 - root_mean_squared_error: 0.1708 - val_loss: 0.0505 - val_root_mean_squared_error: 0.2248\n",
            "Epoch 35/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0282 - root_mean_squared_error: 0.1680 - val_loss: 0.0502 - val_root_mean_squared_error: 0.2241\n",
            "Epoch 36/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0276 - root_mean_squared_error: 0.1660 - val_loss: 0.0486 - val_root_mean_squared_error: 0.2204\n",
            "Epoch 37/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0280 - root_mean_squared_error: 0.1674 - val_loss: 0.0488 - val_root_mean_squared_error: 0.2209\n",
            "Epoch 38/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0274 - root_mean_squared_error: 0.1656 - val_loss: 0.0482 - val_root_mean_squared_error: 0.2196\n",
            "Epoch 39/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0272 - root_mean_squared_error: 0.1650 - val_loss: 0.0487 - val_root_mean_squared_error: 0.2207\n",
            "Epoch 40/40\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0270 - root_mean_squared_error: 0.1644 - val_loss: 0.0487 - val_root_mean_squared_error: 0.2207\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "         Open      High       Low     Close  Adj Close        Volume  \\\n",
            "0    0.034276  0.034276  0.034276  0.034276   0.034276  7.272079e+13   \n",
            "1    0.034276  0.034276  0.034276  0.034276   0.034276  7.272079e+13   \n",
            "2    0.034276  0.034276  0.034276  0.034276   0.034276  7.272079e+13   \n",
            "3    0.034276  0.034276  0.034276  0.034276   0.034276  7.272079e+13   \n",
            "4    0.034276  0.034276  0.034276  0.034276   0.034276  7.272079e+13   \n",
            "..        ...       ...       ...       ...        ...           ...   \n",
            "115  0.034276  0.034276  0.034276  0.034276   0.034276  7.272079e+13   \n",
            "116  0.034276  0.034276  0.034276  0.034276   0.034276  7.272079e+13   \n",
            "117  0.034276  0.034276  0.034276  0.034276   0.034276  7.272079e+13   \n",
            "118  0.034276  0.034276  0.034276  0.034276   0.034276  7.272079e+13   \n",
            "119  0.034276  0.034276  0.034276  0.034276   0.034276  7.272079e+13   \n",
            "\n",
            "            0         1         2         0  ...        21        22  \\\n",
            "0    0.019468 -0.006474  0.982751 -0.006244  ... -0.003031  0.010108   \n",
            "1    0.019468 -0.006474  0.982751 -0.006244  ... -0.003031  0.010108   \n",
            "2    0.019468 -0.006474  0.982751 -0.006244  ... -0.003031  0.010108   \n",
            "3    0.019468 -0.006474  0.982751 -0.006244  ... -0.003031  0.010108   \n",
            "4    0.019468 -0.006474  0.982751 -0.006244  ... -0.003031  0.010108   \n",
            "..        ...       ...       ...       ...  ...       ...       ...   \n",
            "115  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031  0.010108   \n",
            "116  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031  0.010108   \n",
            "117  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031  0.010108   \n",
            "118  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031  0.010108   \n",
            "119  0.019468 -0.006474  0.982751 -0.006244  ... -0.003031  0.010108   \n",
            "\n",
            "           23        24        25        26        27        28        29  \\\n",
            "0    0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507  0.000021   \n",
            "1    0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507  0.000021   \n",
            "2    0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507  0.000021   \n",
            "3    0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507  0.000021   \n",
            "4    0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507  0.000021   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "115  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507  0.000021   \n",
            "116  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507  0.000021   \n",
            "117  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507  0.000021   \n",
            "118  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507  0.000021   \n",
            "119  0.013626  0.022766  0.007235  0.013008  0.008817 -0.026507  0.000021   \n",
            "\n",
            "           30  \n",
            "0   -0.017907  \n",
            "1   -0.017907  \n",
            "2   -0.017907  \n",
            "3   -0.017907  \n",
            "4   -0.017907  \n",
            "..        ...  \n",
            "115 -0.017907  \n",
            "116 -0.017907  \n",
            "117 -0.017907  \n",
            "118 -0.017907  \n",
            "119 -0.017907  \n",
            "\n",
            "[120 rows x 40 columns]\n",
            "           Actual  Predicted\n",
            "0    3.052210e-07   0.034276\n",
            "1    3.034849e-07   0.034276\n",
            "2    3.009333e-07   0.034276\n",
            "3    3.005540e-07   0.034276\n",
            "4    2.962310e-07   0.034276\n",
            "..            ...        ...\n",
            "115  2.970656e-07   0.034276\n",
            "116  2.950631e-07   0.034276\n",
            "117  2.986630e-07   0.034276\n",
            "118  2.983086e-07   0.034276\n",
            "119  2.954335e-07   0.034276\n",
            "\n",
            "[120 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'XEN-USD': (2.954335e-07, 0.0343436488138836)}\n"
          ]
        }
      ],
      "source": [
        "dict_output = {}\n",
        "dict_output = getFuturePrices('XEN', 'USD', dict_output, 30, '2011-01-01', '2024-12-07')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlqSVmyJB13m"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "api_key = '6b1cf277-f71d-4408-9904-6666e5fce0e8'\n",
        "\n",
        "cryptos = []\n",
        "url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
        "\n",
        "for start in range(1, 20000, 5000):\n",
        "\n",
        "    params = {\n",
        "        'start': start,\n",
        "        'limit': 5000,\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        'Accepts': 'application/json',\n",
        "        'X-CMC_PRO_API_KEY': api_key\n",
        "    }\n",
        "\n",
        "    r = requests.get(url, params=params, headers=headers)\n",
        "    data = r.json()\n",
        "\n",
        "    for number, item in enumerate(data['data']):\n",
        "        print(f\"{start+number:4} | {item['symbol']:5} | {item['date_added'][:10]}\")\n",
        "        cryptos.append(item['symbol'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdagB2_FenKh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "edf96171-878d-4efc-a0ba-94035df5d367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ETHDOG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['ETHDOG-BTC']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ETHDOG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['ETHDOG-ETH']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['ETHDOG-USD']: YFInvalidPeriodError(\"%ticker%: Period 'max' is invalid, must be one of ['1d', '5d']\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ETHDOG\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['JOL-BTC']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JOL\n",
            "JOL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['JOL-ETH']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JOL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Open      High       Low     Close  Adj Close        Volume     10  \\\n",
            "0     0.000311  0.000311  0.000311  0.000311   0.000311  1.000000e-09   True   \n",
            "1     0.000311  0.000311  0.000311  0.000311   0.000311  1.000000e-09   True   \n",
            "2     0.000311  0.000311  0.000311  0.000311   0.000311  1.000000e-09   True   \n",
            "3     0.000311  0.000311  0.000311  0.000311   0.000311  1.000000e-09   True   \n",
            "4     0.000310  0.000310  0.000310  0.000310   0.000310  1.000000e-09   True   \n",
            "...        ...       ...       ...       ...        ...           ...    ...   \n",
            "5755  0.000514  0.000514  0.000514  0.000514   0.000514  1.000000e-09  False   \n",
            "5756  0.000514  0.000514  0.000514  0.000514   0.000514  1.000000e-09  False   \n",
            "5757  0.000514  0.000514  0.000514  0.000514   0.000514  1.000000e-09  False   \n",
            "5758  0.000514  0.000514  0.000514  0.000514   0.000514  1.000000e-09  False   \n",
            "5759  0.000514  0.000514  0.000514  0.000514   0.000514  1.000000e-09  False   \n",
            "\n",
            "         11     12      1  ...     22     23     24     25     26     27  \\\n",
            "0     False  False  False  ...  False  False  False  False  False  False   \n",
            "1     False  False  False  ...  False  False  False  False  False  False   \n",
            "2     False  False  False  ...  False  False  False  False  False  False   \n",
            "3     False  False  False  ...  False  False  False  False  False  False   \n",
            "4     False  False  False  ...  False  False  False  False  False  False   \n",
            "...     ...    ...    ...  ...    ...    ...    ...    ...    ...    ...   \n",
            "5755  False   True  False  ...  False  False  False  False  False  False   \n",
            "5756  False   True  False  ...  False  False  False  False  False  False   \n",
            "5757  False   True  False  ...  False  False  False  False  False  False   \n",
            "5758  False   True  False  ...  False  False  False  False  False  False   \n",
            "5759  False   True  False  ...  False  False  False  False  False  False   \n",
            "\n",
            "         28     29     30     31  \n",
            "0     False  False  False  False  \n",
            "1     False  False  False  False  \n",
            "2     False  False  False  False  \n",
            "3     False  False  False  False  \n",
            "4     False  False  False  False  \n",
            "...     ...    ...    ...    ...  \n",
            "5755  False  False  False  False  \n",
            "5756  False  False  False  False  \n",
            "5757  False  False  False  False  \n",
            "5758  False  False  False  False  \n",
            "5759  False  False  False  False  \n",
            "\n",
            "[5760 rows x 40 columns]\n",
            "          Open      High       Low     Close  Adj Close        Volume     10  \\\n",
            "0     0.000311  0.000311  0.000311  0.000311   0.000311  1.000000e-09   True   \n",
            "1     0.000311  0.000311  0.000311  0.000311   0.000311  1.000000e-09   True   \n",
            "2     0.000311  0.000311  0.000311  0.000311   0.000311  1.000000e-09   True   \n",
            "3     0.000311  0.000311  0.000311  0.000311   0.000311  1.000000e-09   True   \n",
            "4     0.000310  0.000310  0.000310  0.000310   0.000310  1.000000e-09   True   \n",
            "...        ...       ...       ...       ...        ...           ...    ...   \n",
            "5755  0.000514  0.000514  0.000514  0.000514   0.000514  1.000000e-09  False   \n",
            "5756  0.000514  0.000514  0.000514  0.000514   0.000514  1.000000e-09  False   \n",
            "5757  0.000514  0.000514  0.000514  0.000514   0.000514  1.000000e-09  False   \n",
            "5758  0.000514  0.000514  0.000514  0.000514   0.000514  1.000000e-09  False   \n",
            "5759  0.000514  0.000514  0.000514  0.000514   0.000514  1.000000e-09  False   \n",
            "\n",
            "         11     12      1  ...     22     23     24     25     26     27  \\\n",
            "0     False  False  False  ...  False  False  False  False  False  False   \n",
            "1     False  False  False  ...  False  False  False  False  False  False   \n",
            "2     False  False  False  ...  False  False  False  False  False  False   \n",
            "3     False  False  False  ...  False  False  False  False  False  False   \n",
            "4     False  False  False  ...  False  False  False  False  False  False   \n",
            "...     ...    ...    ...  ...    ...    ...    ...    ...    ...    ...   \n",
            "5755  False   True  False  ...  False  False  False  False  False  False   \n",
            "5756  False   True  False  ...  False  False  False  False  False  False   \n",
            "5757  False   True  False  ...  False  False  False  False  False  False   \n",
            "5758  False   True  False  ...  False  False  False  False  False  False   \n",
            "5759  False   True  False  ...  False  False  False  False  False  False   \n",
            "\n",
            "         28     29     30     31  \n",
            "0     False  False  False  False  \n",
            "1     False  False  False  False  \n",
            "2     False  False  False  False  \n",
            "3     False  False  False  False  \n",
            "4     False  False  False  False  \n",
            "...     ...    ...    ...    ...  \n",
            "5755  False  False  False  False  \n",
            "5756  False  False  False  False  \n",
            "5757  False  False  False  False  \n",
            "5758  False  False  False  False  \n",
            "5759  False  False  False  False  \n",
            "\n",
            "[5392 rows x 40 columns]\n",
            "       Actual\n",
            "0    0.000514\n",
            "1    0.000514\n",
            "2    0.000514\n",
            "3    0.000514\n",
            "4    0.000514\n",
            "..        ...\n",
            "115  0.000514\n",
            "116  0.000514\n",
            "117  0.000514\n",
            "118  0.000514\n",
            "119  0.000514\n",
            "\n",
            "[120 rows x 1 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d (\u001b[38;5;33mConv1D\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                     \u001b[38;5;34m30,976\u001b[0m \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " average_pooling1d (\u001b[38;5;33mAveragePooling1D\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                    \u001b[38;5;34m196,864\u001b[0m \n",
              "\n",
              " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " average_pooling1d_1                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mAveragePooling1D\u001b[0m)                                                                 \n",
              "\n",
              " lstm (\u001b[38;5;33mLSTM\u001b[0m)                           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                       \u001b[38;5;34m5,028,000\u001b[0m \n",
              "\n",
              " repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " Multi-Head (\u001b[38;5;33mMultiHeadAttention\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                    \u001b[38;5;34m4,004,000\u001b[0m \n",
              "\n",
              " lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                    \u001b[38;5;34m8,004,000\u001b[0m \n",
              "\n",
              " time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m40\u001b[0m)                         \u001b[38;5;34m40,040\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,976</span> \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " average_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> \n",
              "\n",
              " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " average_pooling1d_1                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)                                                                 \n",
              "\n",
              " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,028,000</span> \n",
              "\n",
              " repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " Multi-Head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">4,004,000</span> \n",
              "\n",
              " lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">8,004,000</span> \n",
              "\n",
              " time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">40,040</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,303,880\u001b[0m (66.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,303,880</span> (66.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,303,880\u001b[0m (66.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,303,880</span> (66.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 133ms/step - loss: 0.0944 - root_mean_squared_error: 0.3060 - val_loss: 0.0699 - val_root_mean_squared_error: 0.2645 - learning_rate: 0.0020\n",
            "Epoch 2/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.1188 - root_mean_squared_error: 0.3416 - val_loss: 0.0457 - val_root_mean_squared_error: 0.2139 - learning_rate: 0.0020\n",
            "Epoch 3/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.1305 - root_mean_squared_error: 0.3555 - val_loss: 0.0752 - val_root_mean_squared_error: 0.2742 - learning_rate: 0.0020\n",
            "Epoch 4/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 138ms/step - loss: 0.1187 - root_mean_squared_error: 0.3391 - val_loss: 0.0519 - val_root_mean_squared_error: 0.2277 - learning_rate: 0.0020\n",
            "Epoch 5/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 169ms/step - loss: 0.1113 - root_mean_squared_error: 0.3241 - val_loss: 0.0564 - val_root_mean_squared_error: 0.2374 - learning_rate: 0.0020\n",
            "Epoch 6/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - loss: 0.0915 - root_mean_squared_error: 0.2969 - val_loss: 0.0473 - val_root_mean_squared_error: 0.2175 - learning_rate: 0.0020\n",
            "Epoch 7/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - loss: 0.1809 - root_mean_squared_error: 0.4128 - val_loss: 0.1175 - val_root_mean_squared_error: 0.3428 - learning_rate: 0.0020\n",
            "Epoch 8/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0939 - root_mean_squared_error: 0.3040 - val_loss: 0.0580 - val_root_mean_squared_error: 0.2408 - learning_rate: 0.0020\n",
            "Epoch 9/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.1265 - root_mean_squared_error: 0.3492 - val_loss: 0.0633 - val_root_mean_squared_error: 0.2516 - learning_rate: 0.0020\n",
            "Epoch 10/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0546 - root_mean_squared_error: 0.2333 - val_loss: 0.0652 - val_root_mean_squared_error: 0.2554 - learning_rate: 0.0020\n",
            "Epoch 11/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.1014 - root_mean_squared_error: 0.3128 - val_loss: 0.0448 - val_root_mean_squared_error: 0.2118 - learning_rate: 0.0020\n",
            "Epoch 12/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 258ms/step - loss: 0.0432 - root_mean_squared_error: 0.2075 - val_loss: 0.0671 - val_root_mean_squared_error: 0.2591 - learning_rate: 0.0020\n",
            "Epoch 13/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0756 - root_mean_squared_error: 0.2713 - val_loss: 0.0547 - val_root_mean_squared_error: 0.2339 - learning_rate: 0.0020\n",
            "Epoch 14/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0498 - root_mean_squared_error: 0.2228 - val_loss: 0.0713 - val_root_mean_squared_error: 0.2670 - learning_rate: 0.0020\n",
            "Epoch 15/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0487 - root_mean_squared_error: 0.2202 - val_loss: 0.0530 - val_root_mean_squared_error: 0.2302 - learning_rate: 0.0020\n",
            "Epoch 16/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0649 - root_mean_squared_error: 0.2533 - val_loss: 0.0670 - val_root_mean_squared_error: 0.2589 - learning_rate: 0.0020\n",
            "Epoch 17/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0535 - root_mean_squared_error: 0.2303 - val_loss: 0.0540 - val_root_mean_squared_error: 0.2324 - learning_rate: 0.0020\n",
            "Epoch 18/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0681 - root_mean_squared_error: 0.2587 - val_loss: 0.0592 - val_root_mean_squared_error: 0.2434 - learning_rate: 0.0020\n",
            "Epoch 19/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.1303 - root_mean_squared_error: 0.3491 - val_loss: 0.0547 - val_root_mean_squared_error: 0.2339 - learning_rate: 0.0020\n",
            "Epoch 20/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0496 - root_mean_squared_error: 0.2225 - val_loss: 0.0530 - val_root_mean_squared_error: 0.2303 - learning_rate: 0.0020\n",
            "Epoch 21/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0487 - root_mean_squared_error: 0.2203 - val_loss: 0.0574 - val_root_mean_squared_error: 0.2396 - learning_rate: 0.0020\n",
            "Epoch 22/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0451 - root_mean_squared_error: 0.2120 - val_loss: 0.0600 - val_root_mean_squared_error: 0.2450 - learning_rate: 0.0020\n",
            "Epoch 23/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 0.0389 - root_mean_squared_error: 0.1969 - val_loss: 0.0565 - val_root_mean_squared_error: 0.2377 - learning_rate: 0.0020\n",
            "Epoch 24/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 0.0536 - root_mean_squared_error: 0.2306 - val_loss: 0.0596 - val_root_mean_squared_error: 0.2441 - learning_rate: 0.0020\n",
            "Epoch 25/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0415 - root_mean_squared_error: 0.2034 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2469 - learning_rate: 0.0020\n",
            "Epoch 26/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0624 - root_mean_squared_error: 0.2462 - val_loss: 0.0609 - val_root_mean_squared_error: 0.2467 - learning_rate: 0.0020\n",
            "Epoch 27/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0380 - root_mean_squared_error: 0.1948 - val_loss: 0.0640 - val_root_mean_squared_error: 0.2529 - learning_rate: 0.0020\n",
            "Epoch 28/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - loss: 0.0364 - root_mean_squared_error: 0.1906 - val_loss: 0.0600 - val_root_mean_squared_error: 0.2450 - learning_rate: 0.0020\n",
            "Epoch 29/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0515 - root_mean_squared_error: 0.2263 - val_loss: 0.0683 - val_root_mean_squared_error: 0.2613 - learning_rate: 0.0020\n",
            "Epoch 30/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0406 - root_mean_squared_error: 0.2007 - val_loss: 0.0642 - val_root_mean_squared_error: 0.2534 - learning_rate: 0.0020\n",
            "Epoch 31/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0393 - root_mean_squared_error: 0.1980 - val_loss: 0.0608 - val_root_mean_squared_error: 0.2465 - learning_rate: 0.0020\n",
            "Epoch 32/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0410 - root_mean_squared_error: 0.2022 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2482 - learning_rate: 0.0020\n",
            "Epoch 33/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0403 - root_mean_squared_error: 0.2006 - val_loss: 0.0618 - val_root_mean_squared_error: 0.2485 - learning_rate: 0.0020\n",
            "Epoch 34/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0408 - root_mean_squared_error: 0.2017 - val_loss: 0.0610 - val_root_mean_squared_error: 0.2471 - learning_rate: 0.0020\n",
            "Epoch 35/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0399 - root_mean_squared_error: 0.1996 - val_loss: 0.0615 - val_root_mean_squared_error: 0.2480 - learning_rate: 0.0020\n",
            "Epoch 36/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0413 - root_mean_squared_error: 0.2030 - val_loss: 0.0603 - val_root_mean_squared_error: 0.2455 - learning_rate: 0.0020\n",
            "Epoch 37/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0393 - root_mean_squared_error: 0.1982 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2446 - learning_rate: 0.0020\n",
            "Epoch 38/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0402 - root_mean_squared_error: 0.2003 - val_loss: 0.0610 - val_root_mean_squared_error: 0.2470 - learning_rate: 0.0020\n",
            "Epoch 39/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0441 - root_mean_squared_error: 0.2096 - val_loss: 0.0597 - val_root_mean_squared_error: 0.2444 - learning_rate: 0.0020\n",
            "Epoch 40/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0418 - root_mean_squared_error: 0.2042 - val_loss: 0.0626 - val_root_mean_squared_error: 0.2503 - learning_rate: 0.0020\n",
            "Epoch 41/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0391 - root_mean_squared_error: 0.1975 - val_loss: 0.0615 - val_root_mean_squared_error: 0.2480 - learning_rate: 0.0020\n",
            "Epoch 42/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0516 - root_mean_squared_error: 0.2262 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2429 - learning_rate: 0.0020\n",
            "Epoch 43/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.2010 - root_mean_squared_error: 0.4234 - val_loss: 0.0569 - val_root_mean_squared_error: 0.2386 - learning_rate: 0.0020\n",
            "Epoch 44/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0491 - root_mean_squared_error: 0.2214 - val_loss: 0.0620 - val_root_mean_squared_error: 0.2491 - learning_rate: 0.0020\n",
            "Epoch 45/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0471 - root_mean_squared_error: 0.2164 - val_loss: 0.0594 - val_root_mean_squared_error: 0.2437 - learning_rate: 0.0020\n",
            "Epoch 46/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0470 - root_mean_squared_error: 0.2164 - val_loss: 0.0604 - val_root_mean_squared_error: 0.2457 - learning_rate: 0.0020\n",
            "Epoch 47/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0458 - root_mean_squared_error: 0.2135 - val_loss: 0.0597 - val_root_mean_squared_error: 0.2443 - learning_rate: 0.0020\n",
            "Epoch 48/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0388 - root_mean_squared_error: 0.1969 - val_loss: 0.0597 - val_root_mean_squared_error: 0.2443 - learning_rate: 0.0020\n",
            "Epoch 49/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0356 - root_mean_squared_error: 0.1887 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2446 - learning_rate: 0.0020\n",
            "Epoch 50/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0415 - root_mean_squared_error: 0.2029 - val_loss: 0.0594 - val_root_mean_squared_error: 0.2437 - learning_rate: 0.0020\n",
            "Epoch 51/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0362 - root_mean_squared_error: 0.1901 - val_loss: 0.0599 - val_root_mean_squared_error: 0.2447 - learning_rate: 0.0020\n",
            "Epoch 52/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0355 - root_mean_squared_error: 0.1883 - val_loss: 0.0593 - val_root_mean_squared_error: 0.2435 - learning_rate: 0.0020\n",
            "Epoch 53/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0351 - root_mean_squared_error: 0.1872 - val_loss: 0.0598 - val_root_mean_squared_error: 0.2445 - learning_rate: 0.0020\n",
            "Epoch 54/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0349 - root_mean_squared_error: 0.1866 - val_loss: 0.0595 - val_root_mean_squared_error: 0.2439 - learning_rate: 0.0020\n",
            "Epoch 55/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 0.0342 - root_mean_squared_error: 0.1848 - val_loss: 0.0596 - val_root_mean_squared_error: 0.2442 - learning_rate: 0.0020\n",
            "Epoch 56/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0339 - root_mean_squared_error: 0.1840 - val_loss: 0.0596 - val_root_mean_squared_error: 0.2441 - learning_rate: 0.0020\n",
            "Epoch 57/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0536 - root_mean_squared_error: 0.2290 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2429 - learning_rate: 0.0020\n",
            "Epoch 58/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0352 - root_mean_squared_error: 0.1874 - val_loss: 0.0595 - val_root_mean_squared_error: 0.2440 - learning_rate: 0.0020\n",
            "Epoch 59/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0345 - root_mean_squared_error: 0.1855 - val_loss: 0.0591 - val_root_mean_squared_error: 0.2431 - learning_rate: 0.0020\n",
            "Epoch 60/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0348 - root_mean_squared_error: 0.1864 - val_loss: 0.0596 - val_root_mean_squared_error: 0.2442 - learning_rate: 0.0020\n",
            "Epoch 61/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0326 - root_mean_squared_error: 0.1805 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2430 - learning_rate: 0.0020\n",
            "Epoch 62/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.0314 - root_mean_squared_error: 0.1772 - val_loss: 0.0592 - val_root_mean_squared_error: 0.2434 - learning_rate: 0.0020\n",
            "Epoch 63/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0299 - root_mean_squared_error: 0.1728 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2429 - learning_rate: 0.0020\n",
            "Epoch 64/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0301 - root_mean_squared_error: 0.1733 - val_loss: 0.0574 - val_root_mean_squared_error: 0.2395 - learning_rate: 0.0020\n",
            "Epoch 65/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0298 - root_mean_squared_error: 0.1726 - val_loss: 0.0582 - val_root_mean_squared_error: 0.2412 - learning_rate: 0.0020\n",
            "Epoch 66/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0306 - root_mean_squared_error: 0.1748 - val_loss: 0.0552 - val_root_mean_squared_error: 0.2350 - learning_rate: 0.0020\n",
            "Epoch 67/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0366 - root_mean_squared_error: 0.1909 - val_loss: 0.0659 - val_root_mean_squared_error: 0.2567 - learning_rate: 0.0020\n",
            "Epoch 68/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0322 - root_mean_squared_error: 0.1794 - val_loss: 0.0683 - val_root_mean_squared_error: 0.2613 - learning_rate: 0.0020\n",
            "Epoch 69/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0386 - root_mean_squared_error: 0.1958 - val_loss: 0.0597 - val_root_mean_squared_error: 0.2444 - learning_rate: 0.0020\n",
            "Epoch 70/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0333 - root_mean_squared_error: 0.1823 - val_loss: 0.0610 - val_root_mean_squared_error: 0.2470 - learning_rate: 0.0020\n",
            "Epoch 71/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0324 - root_mean_squared_error: 0.1797 - val_loss: 0.0637 - val_root_mean_squared_error: 0.2523 - learning_rate: 0.0020\n",
            "Epoch 72/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0312 - root_mean_squared_error: 0.1766 - val_loss: 0.0573 - val_root_mean_squared_error: 0.2394 - learning_rate: 0.0020\n",
            "Epoch 73/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0313 - root_mean_squared_error: 0.1769 - val_loss: 0.0613 - val_root_mean_squared_error: 0.2477 - learning_rate: 0.0020\n",
            "Epoch 74/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0310 - root_mean_squared_error: 0.1759 - val_loss: 0.0582 - val_root_mean_squared_error: 0.2412 - learning_rate: 0.0020\n",
            "Epoch 75/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0309 - root_mean_squared_error: 0.1756 - val_loss: 0.0596 - val_root_mean_squared_error: 0.2441 - learning_rate: 0.0020\n",
            "Epoch 76/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0309 - root_mean_squared_error: 0.1756 - val_loss: 0.0593 - val_root_mean_squared_error: 0.2435 - learning_rate: 0.0020\n",
            "Epoch 77/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0306 - root_mean_squared_error: 0.1748 - val_loss: 0.0585 - val_root_mean_squared_error: 0.2420 - learning_rate: 0.0020\n",
            "Epoch 78/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0308 - root_mean_squared_error: 0.1753 - val_loss: 0.0589 - val_root_mean_squared_error: 0.2427 - learning_rate: 0.0020\n",
            "Epoch 79/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0304 - root_mean_squared_error: 0.1743 - val_loss: 0.0578 - val_root_mean_squared_error: 0.2404 - learning_rate: 0.0020\n",
            "Epoch 80/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0305 - root_mean_squared_error: 0.1745 - val_loss: 0.0594 - val_root_mean_squared_error: 0.2438 - learning_rate: 0.0020\n",
            "Epoch 81/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0302 - root_mean_squared_error: 0.1736 - val_loss: 0.0587 - val_root_mean_squared_error: 0.2422 - learning_rate: 0.0020\n",
            "Epoch 82/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0306 - root_mean_squared_error: 0.1748 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2429 - learning_rate: 0.0020\n",
            "Epoch 83/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0586 - val_root_mean_squared_error: 0.2420 - learning_rate: 0.0020\n",
            "Epoch 84/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0307 - root_mean_squared_error: 0.1750 - val_loss: 0.0589 - val_root_mean_squared_error: 0.2427 - learning_rate: 0.0020\n",
            "Epoch 85/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0300 - root_mean_squared_error: 0.1731 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2429 - learning_rate: 0.0020\n",
            "Epoch 86/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0302 - root_mean_squared_error: 0.1735 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2429 - learning_rate: 0.0020\n",
            "Epoch 87/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0299 - root_mean_squared_error: 0.1728 - val_loss: 0.0593 - val_root_mean_squared_error: 0.2435 - learning_rate: 0.0020\n",
            "Epoch 88/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0300 - root_mean_squared_error: 0.1731 - val_loss: 0.0596 - val_root_mean_squared_error: 0.2441 - learning_rate: 0.0020\n",
            "Epoch 89/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0300 - root_mean_squared_error: 0.1730 - val_loss: 0.0589 - val_root_mean_squared_error: 0.2427 - learning_rate: 0.0020\n",
            "Epoch 90/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0312 - root_mean_squared_error: 0.1765 - val_loss: 0.0590 - val_root_mean_squared_error: 0.2428 - learning_rate: 0.0020\n",
            "Epoch 91/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0305 - root_mean_squared_error: 0.1746 - val_loss: 0.0588 - val_root_mean_squared_error: 0.2425 - learning_rate: 0.0020\n",
            "Epoch 92/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0302 - root_mean_squared_error: 0.1737 - val_loss: 0.0585 - val_root_mean_squared_error: 0.2419 - learning_rate: 0.0020\n",
            "Epoch 93/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0301 - root_mean_squared_error: 0.1733 - val_loss: 0.0588 - val_root_mean_squared_error: 0.2425 - learning_rate: 0.0020\n",
            "Epoch 94/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0299 - root_mean_squared_error: 0.1728 - val_loss: 0.0587 - val_root_mean_squared_error: 0.2423 - learning_rate: 0.0020\n",
            "Epoch 95/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0298 - root_mean_squared_error: 0.1724 - val_loss: 0.0582 - val_root_mean_squared_error: 0.2413 - learning_rate: 0.0020\n",
            "Epoch 96/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0299 - root_mean_squared_error: 0.1727 - val_loss: 0.0584 - val_root_mean_squared_error: 0.2416 - learning_rate: 0.0020\n",
            "Epoch 97/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.0297 - root_mean_squared_error: 0.1723 - val_loss: 0.0585 - val_root_mean_squared_error: 0.2418 - learning_rate: 0.0020\n",
            "Epoch 98/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0301 - root_mean_squared_error: 0.1733 - val_loss: 0.0582 - val_root_mean_squared_error: 0.2412 - learning_rate: 0.0020\n",
            "Epoch 99/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0298 - root_mean_squared_error: 0.1724 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2410 - learning_rate: 0.0020\n",
            "Epoch 100/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0298 - root_mean_squared_error: 0.1724 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2411 - learning_rate: 0.0020\n",
            "Epoch 101/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0296 - root_mean_squared_error: 0.1719 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2410 - learning_rate: 0.0020\n",
            "Epoch 102/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0296 - root_mean_squared_error: 0.1718 - val_loss: 0.0579 - val_root_mean_squared_error: 0.2407 - learning_rate: 0.0020\n",
            "Epoch 103/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - loss: 0.0294 - root_mean_squared_error: 0.1714 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2411 - learning_rate: 0.0020\n",
            "Epoch 104/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - loss: 0.0293 - root_mean_squared_error: 0.1712 - val_loss: 0.0582 - val_root_mean_squared_error: 0.2412 - learning_rate: 0.0020\n",
            "Epoch 105/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 141ms/step - loss: 0.0293 - root_mean_squared_error: 0.1711 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2411 - learning_rate: 0.0020\n",
            "Epoch 106/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0293 - root_mean_squared_error: 0.1711 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2411 - learning_rate: 0.0020\n",
            "Epoch 107/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0294 - root_mean_squared_error: 0.1712 - val_loss: 0.0581 - val_root_mean_squared_error: 0.2411 - learning_rate: 0.0020\n",
            "Epoch 108/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0298 - root_mean_squared_error: 0.1725 - val_loss: 0.0680 - val_root_mean_squared_error: 0.2608 - learning_rate: 0.0020\n",
            "Epoch 109/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0310 - root_mean_squared_error: 0.1758 - val_loss: 0.0608 - val_root_mean_squared_error: 0.2466 - learning_rate: 0.0020\n",
            "Epoch 110/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0294 - root_mean_squared_error: 0.1715 - val_loss: 0.0584 - val_root_mean_squared_error: 0.2416 - learning_rate: 0.0020\n",
            "Epoch 111/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0297 - root_mean_squared_error: 0.1722 - val_loss: 0.0574 - val_root_mean_squared_error: 0.2396 - learning_rate: 0.0020\n",
            "Epoch 112/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0299 - root_mean_squared_error: 0.1727 - val_loss: 0.0555 - val_root_mean_squared_error: 0.2356 - learning_rate: 0.0020\n",
            "Epoch 113/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0302 - root_mean_squared_error: 0.1735 - val_loss: 0.0570 - val_root_mean_squared_error: 0.2387 - learning_rate: 0.0020\n",
            "Epoch 114/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0305 - root_mean_squared_error: 0.1746 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2352 - learning_rate: 0.0020\n",
            "Epoch 115/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0308 - root_mean_squared_error: 0.1752 - val_loss: 0.0567 - val_root_mean_squared_error: 0.2382 - learning_rate: 0.0020\n",
            "Epoch 116/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0307 - root_mean_squared_error: 0.1751 - val_loss: 0.0554 - val_root_mean_squared_error: 0.2353 - learning_rate: 0.0020\n",
            "Epoch 117/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0305 - root_mean_squared_error: 0.1746 - val_loss: 0.0567 - val_root_mean_squared_error: 0.2380 - learning_rate: 0.0020\n",
            "Epoch 118/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2353 - learning_rate: 0.0020\n",
            "Epoch 119/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0300 - root_mean_squared_error: 0.1731 - val_loss: 0.0566 - val_root_mean_squared_error: 0.2380 - learning_rate: 0.0020\n",
            "Epoch 120/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0298 - root_mean_squared_error: 0.1725 - val_loss: 0.0554 - val_root_mean_squared_error: 0.2354 - learning_rate: 0.0020\n",
            "Epoch 121/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0297 - root_mean_squared_error: 0.1721 - val_loss: 0.0567 - val_root_mean_squared_error: 0.2381 - learning_rate: 0.0020\n",
            "Epoch 122/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 287ms/step - loss: 0.0296 - root_mean_squared_error: 0.1718 - val_loss: 0.0556 - val_root_mean_squared_error: 0.2358 - learning_rate: 0.0020\n",
            "Epoch 123/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - loss: 0.0295 - root_mean_squared_error: 0.1716 - val_loss: 0.0564 - val_root_mean_squared_error: 0.2375 - learning_rate: 0.0020\n",
            "Epoch 124/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.0295 - root_mean_squared_error: 0.1717 - val_loss: 0.0555 - val_root_mean_squared_error: 0.2355 - learning_rate: 0.0020\n",
            "Epoch 125/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 224ms/step - loss: 0.0294 - root_mean_squared_error: 0.1713 - val_loss: 0.0562 - val_root_mean_squared_error: 0.2372 - learning_rate: 0.0020\n",
            "Epoch 126/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0295 - root_mean_squared_error: 0.1717 - val_loss: 0.0556 - val_root_mean_squared_error: 0.2359 - learning_rate: 0.0020\n",
            "Epoch 127/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0302 - root_mean_squared_error: 0.1736 - val_loss: 0.0566 - val_root_mean_squared_error: 0.2380 - learning_rate: 0.0020\n",
            "Epoch 128/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0300 - root_mean_squared_error: 0.1730 - val_loss: 0.0554 - val_root_mean_squared_error: 0.2354 - learning_rate: 0.0020\n",
            "Epoch 129/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0301 - root_mean_squared_error: 0.1734 - val_loss: 0.0572 - val_root_mean_squared_error: 0.2391 - learning_rate: 0.0020\n",
            "Epoch 130/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0296 - root_mean_squared_error: 0.1721 - val_loss: 0.0570 - val_root_mean_squared_error: 0.2387 - learning_rate: 0.0020\n",
            "Epoch 131/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0299 - root_mean_squared_error: 0.1727 - val_loss: 0.0565 - val_root_mean_squared_error: 0.2377 - learning_rate: 0.0020\n",
            "Epoch 132/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0295 - root_mean_squared_error: 0.1717 - val_loss: 0.0527 - val_root_mean_squared_error: 0.2296 - learning_rate: 0.0020\n",
            "Epoch 133/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0304 - root_mean_squared_error: 0.1742 - val_loss: 0.0542 - val_root_mean_squared_error: 0.2328 - learning_rate: 0.0020\n",
            "Epoch 134/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0549 - val_root_mean_squared_error: 0.2343 - learning_rate: 0.0020\n",
            "Epoch 135/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0302 - root_mean_squared_error: 0.1736 - val_loss: 0.0507 - val_root_mean_squared_error: 0.2251 - learning_rate: 0.0020\n",
            "Epoch 136/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0321 - root_mean_squared_error: 0.1791 - val_loss: 0.0524 - val_root_mean_squared_error: 0.2290 - learning_rate: 0.0020\n",
            "Epoch 137/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0294 - root_mean_squared_error: 0.1714 - val_loss: 0.0564 - val_root_mean_squared_error: 0.2375 - learning_rate: 0.0020\n",
            "Epoch 138/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0293 - root_mean_squared_error: 0.1710 - val_loss: 0.0548 - val_root_mean_squared_error: 0.2341 - learning_rate: 0.0020\n",
            "Epoch 139/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 256ms/step - loss: 0.0293 - root_mean_squared_error: 0.1710 - val_loss: 0.0525 - val_root_mean_squared_error: 0.2290 - learning_rate: 0.0020\n",
            "Epoch 140/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0303 - root_mean_squared_error: 0.1739 - val_loss: 0.0508 - val_root_mean_squared_error: 0.2254 - learning_rate: 0.0020\n",
            "Epoch 141/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0299 - root_mean_squared_error: 0.1728 - val_loss: 0.0515 - val_root_mean_squared_error: 0.2268 - learning_rate: 0.0020\n",
            "Epoch 142/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0309 - root_mean_squared_error: 0.1756 - val_loss: 0.0508 - val_root_mean_squared_error: 0.2253 - learning_rate: 0.0020\n",
            "Epoch 143/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0291 - root_mean_squared_error: 0.1706 - val_loss: 0.0477 - val_root_mean_squared_error: 0.2183 - learning_rate: 0.0020\n",
            "Epoch 144/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0312 - root_mean_squared_error: 0.1766 - val_loss: 0.0453 - val_root_mean_squared_error: 0.2128 - learning_rate: 0.0020\n",
            "Epoch 145/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0295 - root_mean_squared_error: 0.1715 - val_loss: 0.0422 - val_root_mean_squared_error: 0.2054 - learning_rate: 0.0020\n",
            "Epoch 146/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0313 - root_mean_squared_error: 0.1766 - val_loss: 0.0400 - val_root_mean_squared_error: 0.2001 - learning_rate: 0.0020\n",
            "Epoch 147/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0300 - root_mean_squared_error: 0.1730 - val_loss: 0.0392 - val_root_mean_squared_error: 0.1981 - learning_rate: 0.0020\n",
            "Epoch 148/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0315 - root_mean_squared_error: 0.1774 - val_loss: 0.0377 - val_root_mean_squared_error: 0.1941 - learning_rate: 0.0020\n",
            "Epoch 149/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0308 - root_mean_squared_error: 0.1755 - val_loss: 0.0361 - val_root_mean_squared_error: 0.1900 - learning_rate: 0.0020\n",
            "Epoch 150/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0361 - root_mean_squared_error: 0.1898 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1914 - learning_rate: 0.0020\n",
            "Epoch 151/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0314 - root_mean_squared_error: 0.1770 - val_loss: 0.0341 - val_root_mean_squared_error: 0.1847 - learning_rate: 0.0020\n",
            "Epoch 152/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0323 - root_mean_squared_error: 0.1795 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1801 - learning_rate: 0.0020\n",
            "Epoch 153/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0300 - root_mean_squared_error: 0.1731 - val_loss: 0.0321 - val_root_mean_squared_error: 0.1791 - learning_rate: 0.0020\n",
            "Epoch 154/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0300 - root_mean_squared_error: 0.1731 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1788 - learning_rate: 0.0020\n",
            "Epoch 155/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0298 - root_mean_squared_error: 0.1724 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1778 - learning_rate: 0.0020\n",
            "Epoch 156/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - loss: 0.0302 - root_mean_squared_error: 0.1736 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1766 - learning_rate: 0.0020\n",
            "Epoch 157/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0302 - root_mean_squared_error: 0.1738 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1781 - learning_rate: 0.0020\n",
            "Epoch 158/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - loss: 0.0299 - root_mean_squared_error: 0.1727 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1737 - learning_rate: 0.0020\n",
            "Epoch 159/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0295 - root_mean_squared_error: 0.1716 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1766 - learning_rate: 0.0020\n",
            "Epoch 160/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 205ms/step - loss: 0.0284 - root_mean_squared_error: 0.1685 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1737 - learning_rate: 0.0020\n",
            "Epoch 161/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0289 - root_mean_squared_error: 0.1700 - val_loss: 0.0314 - val_root_mean_squared_error: 0.1772 - learning_rate: 0.0020\n",
            "Epoch 162/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0290 - root_mean_squared_error: 0.1701 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1726 - learning_rate: 0.0020\n",
            "Epoch 163/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0294 - root_mean_squared_error: 0.1713 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1751 - learning_rate: 0.0020\n",
            "Epoch 164/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0291 - root_mean_squared_error: 0.1703 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1747 - learning_rate: 0.0020\n",
            "Epoch 165/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0289 - root_mean_squared_error: 0.1697 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740 - learning_rate: 0.0020\n",
            "Epoch 166/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0284 - root_mean_squared_error: 0.1683 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1762 - learning_rate: 0.0020\n",
            "Epoch 167/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 230ms/step - loss: 0.0282 - root_mean_squared_error: 0.1678 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1724 - learning_rate: 0.0020\n",
            "Epoch 168/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0282 - root_mean_squared_error: 0.1677 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1774 - learning_rate: 0.0020\n",
            "Epoch 169/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 237ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1724 - learning_rate: 0.0020\n",
            "Epoch 170/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0288 - root_mean_squared_error: 0.1695 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1759 - learning_rate: 0.0020\n",
            "Epoch 171/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0291 - root_mean_squared_error: 0.1704 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1728 - learning_rate: 0.0020\n",
            "Epoch 172/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0292 - root_mean_squared_error: 0.1708 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1739 - learning_rate: 0.0020\n",
            "Epoch 173/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0286 - root_mean_squared_error: 0.1691 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1752 - learning_rate: 0.0020\n",
            "Epoch 174/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0282 - root_mean_squared_error: 0.1678 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1738 - learning_rate: 0.0020\n",
            "Epoch 175/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0282 - root_mean_squared_error: 0.1677 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1757 - learning_rate: 0.0020\n",
            "Epoch 176/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0281 - root_mean_squared_error: 0.1675 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1733 - learning_rate: 0.0020\n",
            "Epoch 177/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 163ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1749 - learning_rate: 0.0020\n",
            "Epoch 178/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - loss: 0.0283 - root_mean_squared_error: 0.1680 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1738 - learning_rate: 0.0020\n",
            "Epoch 179/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0281 - root_mean_squared_error: 0.1674 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1748 - learning_rate: 0.0020\n",
            "Epoch 180/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0282 - root_mean_squared_error: 0.1677 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1742 - learning_rate: 0.0020\n",
            "Epoch 181/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1746 - learning_rate: 0.0020\n",
            "Epoch 182/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1746 - learning_rate: 0.0020\n",
            "Epoch 183/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0283 - root_mean_squared_error: 0.1682 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740 - learning_rate: 0.0020\n",
            "Epoch 184/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0280 - root_mean_squared_error: 0.1671 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1752 - learning_rate: 0.0020\n",
            "Epoch 185/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0283 - root_mean_squared_error: 0.1681 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1739 - learning_rate: 0.0020\n",
            "Epoch 186/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1757 - learning_rate: 0.0020\n",
            "Epoch 187/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0287 - root_mean_squared_error: 0.1692 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1754 - learning_rate: 0.0020\n",
            "Epoch 188/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1750 - learning_rate: 0.0020\n",
            "Epoch 189/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0282 - root_mean_squared_error: 0.1678 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1744 - learning_rate: 0.0020\n",
            "Epoch 190/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1742 - learning_rate: 0.0020\n",
            "Epoch 191/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0282 - root_mean_squared_error: 0.1678 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1744 - learning_rate: 0.0020\n",
            "Epoch 192/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0286 - root_mean_squared_error: 0.1688 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1751 - learning_rate: 0.0020\n",
            "Epoch 193/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0280 - root_mean_squared_error: 0.1671 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1748 - learning_rate: 0.0020\n",
            "Epoch 194/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0282 - root_mean_squared_error: 0.1677 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1733 - learning_rate: 0.0020\n",
            "Epoch 195/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0279 - root_mean_squared_error: 0.1669 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1755 - learning_rate: 0.0020\n",
            "Epoch 196/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 0.0279 - root_mean_squared_error: 0.1667 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1739 - learning_rate: 0.0020\n",
            "Epoch 197/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0282 - root_mean_squared_error: 0.1676 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1756 - learning_rate: 0.0020\n",
            "Epoch 198/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1739 - learning_rate: 0.0020\n",
            "Epoch 199/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0282 - root_mean_squared_error: 0.1676 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1741 - learning_rate: 0.0020\n",
            "Epoch 200/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0281 - root_mean_squared_error: 0.1674 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1751 - learning_rate: 0.0020\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 965ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Open      High       Low     Close  Adj Close        Volume  \\\n",
            "0    0.000501  0.000501  0.000501  0.000501   0.000501  1.115115e-09   \n",
            "1    0.000501  0.000501  0.000501  0.000501   0.000501  1.115115e-09   \n",
            "2    0.000501  0.000501  0.000501  0.000501   0.000501  1.115115e-09   \n",
            "3    0.000501  0.000501  0.000501  0.000501   0.000501  1.115115e-09   \n",
            "4    0.000501  0.000501  0.000501  0.000501   0.000501  1.115115e-09   \n",
            "..        ...       ...       ...       ...        ...           ...   \n",
            "115  0.000501  0.000501  0.000501  0.000501   0.000501  1.115115e-09   \n",
            "116  0.000501  0.000501  0.000501  0.000501   0.000501  1.115115e-09   \n",
            "117  0.000501  0.000501  0.000501  0.000501   0.000501  1.115115e-09   \n",
            "118  0.000501  0.000501  0.000501  0.000501   0.000501  1.115115e-09   \n",
            "119  0.000501  0.000501  0.000501  0.000501   0.000501  1.115115e-09   \n",
            "\n",
            "            0         1         2         0  ...        21        22  \\\n",
            "0   -0.000312  0.001244  0.998579  0.113429  ... -0.000029  0.000529   \n",
            "1   -0.000312  0.001244  0.998579  0.113429  ... -0.000029  0.000529   \n",
            "2   -0.000312  0.001244  0.998579  0.113429  ... -0.000029  0.000529   \n",
            "3   -0.000312  0.001244  0.998579  0.113429  ... -0.000029  0.000529   \n",
            "4   -0.000312  0.001244  0.998579  0.113429  ... -0.000029  0.000529   \n",
            "..        ...       ...       ...       ...  ...       ...       ...   \n",
            "115 -0.000312  0.001244  0.998579  0.113429  ... -0.000029  0.000529   \n",
            "116 -0.000312  0.001244  0.998579  0.113429  ... -0.000029  0.000529   \n",
            "117 -0.000312  0.001244  0.998579  0.113429  ... -0.000029  0.000529   \n",
            "118 -0.000312  0.001244  0.998579  0.113429  ... -0.000029  0.000529   \n",
            "119 -0.000312  0.001244  0.998579  0.113429  ... -0.000029  0.000529   \n",
            "\n",
            "           23        24        25        26        27        28        29  \\\n",
            "0    0.000695  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946   \n",
            "1    0.000695  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946   \n",
            "2    0.000695  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946   \n",
            "3    0.000695  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946   \n",
            "4    0.000695  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946   \n",
            "..        ...       ...       ...       ...       ...       ...       ...   \n",
            "115  0.000695  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946   \n",
            "116  0.000695  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946   \n",
            "117  0.000695  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946   \n",
            "118  0.000695  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946   \n",
            "119  0.000695  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946   \n",
            "\n",
            "           30  \n",
            "0    0.014134  \n",
            "1    0.014134  \n",
            "2    0.014134  \n",
            "3    0.014134  \n",
            "4    0.014134  \n",
            "..        ...  \n",
            "115  0.014134  \n",
            "116  0.014134  \n",
            "117  0.014134  \n",
            "118  0.014134  \n",
            "119  0.014134  \n",
            "\n",
            "[120 rows x 40 columns]\n",
            "       Actual  Predicted\n",
            "0    0.000514   0.000501\n",
            "1    0.000514   0.000501\n",
            "2    0.000514   0.000501\n",
            "3    0.000514   0.000501\n",
            "4    0.000514   0.000501\n",
            "..        ...        ...\n",
            "115  0.000514   0.000501\n",
            "116  0.000514   0.000501\n",
            "117  0.000514   0.000501\n",
            "118  0.000514   0.000501\n",
            "119  0.000514   0.000501\n",
            "\n",
            "[120 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'JOL-USD': (0.0005139758, 0.0005007915577768809)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2acd743933a4>:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:194: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:201: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:201: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:201: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:201: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:201: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:201: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_layer_1              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m40\u001b[0m)                       \u001b[38;5;34m0\u001b[0m  -                      \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                                              \n",
              "\n",
              " lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)              [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,        \u001b[38;5;34m9,246,000\u001b[0m  input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              "                            \u001b[38;5;34m1500\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1500\u001b[0m)]                                           \n",
              "\n",
              " repeat_vector_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1500\u001b[0m)                      \u001b[38;5;34m0\u001b[0m  lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
              " (\u001b[38;5;33mRepeatVector\u001b[0m)                                                                            \n",
              "\n",
              " multi_head_attention       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1500\u001b[0m)              \u001b[38;5;34m9,006,000\u001b[0m  repeat_vector_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mMultiHeadAttention\u001b[0m)                                                                      \n",
              "\n",
              " lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1500\u001b[0m)             \u001b[38;5;34m18,006,000\u001b[0m  multi_head_attention[\u001b[38;5;34m\u001b[0m \n",
              "                                                                    lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],          \n",
              "                                                                    lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]           \n",
              "\n",
              " time_distributed_1         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m40\u001b[0m)                   \u001b[38;5;34m60,040\u001b[0m  lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           \n",
              " (\u001b[38;5;33mTimeDistributed\u001b[0m)                                                                         \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)              </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">        Param # </span><span style=\"font-weight: bold\"> Connected to           </span>\n",
              "\n",
              " input_layer_1              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                                              \n",
              "\n",
              " lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,        <span style=\"color: #00af00; text-decoration-color: #00af00\">9,246,000</span>  input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              "                            <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)]                                           \n",
              "\n",
              " repeat_vector_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)                                                                            \n",
              "\n",
              " multi_head_attention       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">9,006,000</span>  repeat_vector_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)                                                                      \n",
              "\n",
              " lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1500</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">18,006,000</span>  multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                                    lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],          \n",
              "                                                                    lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]           \n",
              "\n",
              " time_distributed_1         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">60,040</span>  lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                                                                         \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,318,040\u001b[0m (138.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,318,040</span> (138.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,318,040\u001b[0m (138.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,318,040</span> (138.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0273 - root_mean_squared_error: 0.1652 - val_loss: 0.0718 - val_root_mean_squared_error: 0.2679\n",
            "Epoch 2/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0260 - root_mean_squared_error: 0.1612 - val_loss: 0.0688 - val_root_mean_squared_error: 0.2623\n",
            "Epoch 3/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0247 - root_mean_squared_error: 0.1572 - val_loss: 0.0659 - val_root_mean_squared_error: 0.2567\n",
            "Epoch 4/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0239 - root_mean_squared_error: 0.1545 - val_loss: 0.0637 - val_root_mean_squared_error: 0.2524\n",
            "Epoch 5/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0240 - root_mean_squared_error: 0.1550 - val_loss: 0.0625 - val_root_mean_squared_error: 0.2500\n",
            "Epoch 6/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0235 - root_mean_squared_error: 0.1533 - val_loss: 0.0618 - val_root_mean_squared_error: 0.2487\n",
            "Epoch 7/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0228 - root_mean_squared_error: 0.1511 - val_loss: 0.0614 - val_root_mean_squared_error: 0.2478\n",
            "Epoch 8/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0613 - val_root_mean_squared_error: 0.2476\n",
            "Epoch 9/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0229 - root_mean_squared_error: 0.1514 - val_loss: 0.0613 - val_root_mean_squared_error: 0.2475\n",
            "Epoch 10/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0221 - root_mean_squared_error: 0.1487 - val_loss: 0.0612 - val_root_mean_squared_error: 0.2474\n",
            "Epoch 11/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0221 - root_mean_squared_error: 0.1485 - val_loss: 0.0613 - val_root_mean_squared_error: 0.2476\n",
            "Epoch 12/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0217 - root_mean_squared_error: 0.1474 - val_loss: 0.0615 - val_root_mean_squared_error: 0.2480\n",
            "Epoch 13/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0217 - root_mean_squared_error: 0.1473 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2481\n",
            "Epoch 14/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0219 - root_mean_squared_error: 0.1479 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2482\n",
            "Epoch 15/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0211 - root_mean_squared_error: 0.1453 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2482\n",
            "Epoch 16/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0213 - root_mean_squared_error: 0.1458 - val_loss: 0.0617 - val_root_mean_squared_error: 0.2483\n",
            "Epoch 17/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0614 - val_root_mean_squared_error: 0.2477\n",
            "Epoch 18/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0212 - root_mean_squared_error: 0.1455 - val_loss: 0.0614 - val_root_mean_squared_error: 0.2478\n",
            "Epoch 19/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0210 - root_mean_squared_error: 0.1448 - val_loss: 0.0614 - val_root_mean_squared_error: 0.2479\n",
            "Epoch 20/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0207 - root_mean_squared_error: 0.1438 - val_loss: 0.0616 - val_root_mean_squared_error: 0.2482\n",
            "Epoch 21/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0208 - root_mean_squared_error: 0.1440 - val_loss: 0.0617 - val_root_mean_squared_error: 0.2484\n",
            "Epoch 22/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0207 - root_mean_squared_error: 0.1438 - val_loss: 0.0618 - val_root_mean_squared_error: 0.2486\n",
            "Epoch 23/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0205 - root_mean_squared_error: 0.1433 - val_loss: 0.0619 - val_root_mean_squared_error: 0.2487\n",
            "Epoch 24/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0203 - root_mean_squared_error: 0.1425 - val_loss: 0.0618 - val_root_mean_squared_error: 0.2486\n",
            "Epoch 25/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0204 - root_mean_squared_error: 0.1428 - val_loss: 0.0619 - val_root_mean_squared_error: 0.2487\n",
            "Epoch 26/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0204 - root_mean_squared_error: 0.1427 - val_loss: 0.0622 - val_root_mean_squared_error: 0.2494\n",
            "Epoch 27/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0205 - root_mean_squared_error: 0.1432 - val_loss: 0.0627 - val_root_mean_squared_error: 0.2503\n",
            "Epoch 28/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0203 - root_mean_squared_error: 0.1425 - val_loss: 0.0630 - val_root_mean_squared_error: 0.2509\n",
            "Epoch 29/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0202 - root_mean_squared_error: 0.1420 - val_loss: 0.0629 - val_root_mean_squared_error: 0.2508\n",
            "Epoch 30/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0201 - root_mean_squared_error: 0.1418 - val_loss: 0.0628 - val_root_mean_squared_error: 0.2505\n",
            "Epoch 31/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0203 - root_mean_squared_error: 0.1425 - val_loss: 0.0625 - val_root_mean_squared_error: 0.2501\n",
            "Epoch 32/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0202 - root_mean_squared_error: 0.1423 - val_loss: 0.0623 - val_root_mean_squared_error: 0.2497\n",
            "Epoch 33/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0203 - root_mean_squared_error: 0.1424 - val_loss: 0.0622 - val_root_mean_squared_error: 0.2493\n",
            "Epoch 34/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0202 - root_mean_squared_error: 0.1421 - val_loss: 0.0621 - val_root_mean_squared_error: 0.2492\n",
            "Epoch 35/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0201 - root_mean_squared_error: 0.1418 - val_loss: 0.0622 - val_root_mean_squared_error: 0.2494\n",
            "Epoch 36/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0200 - root_mean_squared_error: 0.1414 - val_loss: 0.0624 - val_root_mean_squared_error: 0.2497\n",
            "Epoch 37/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0201 - root_mean_squared_error: 0.1419 - val_loss: 0.0627 - val_root_mean_squared_error: 0.2504\n",
            "Epoch 38/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0198 - root_mean_squared_error: 0.1407 - val_loss: 0.0628 - val_root_mean_squared_error: 0.2506\n",
            "Epoch 39/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0203 - root_mean_squared_error: 0.1424 - val_loss: 0.0627 - val_root_mean_squared_error: 0.2505\n",
            "Epoch 40/40\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0198 - root_mean_squared_error: 0.1405 - val_loss: 0.0627 - val_root_mean_squared_error: 0.2505\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Called here\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "         Open      High       Low     Close  Adj Close    Volume         0  \\\n",
            "0    0.000045  0.000045  0.000045  0.000045   0.000045  0.000045 -0.000312   \n",
            "1    0.000045  0.000045  0.000045  0.000045   0.000045  0.000045 -0.000312   \n",
            "2    0.000045  0.000045  0.000045  0.000045   0.000045  0.000045 -0.000312   \n",
            "3    0.000045  0.000045  0.000045  0.000045   0.000045  0.000045 -0.000312   \n",
            "4    0.000045  0.000045  0.000045  0.000045   0.000045  0.000045 -0.000312   \n",
            "..        ...       ...       ...       ...        ...       ...       ...   \n",
            "115  0.000045  0.000045  0.000045  0.000045   0.000045  0.000045 -0.000312   \n",
            "116  0.000045  0.000045  0.000045  0.000045   0.000045  0.000045 -0.000312   \n",
            "117  0.000045  0.000045  0.000045  0.000045   0.000045  0.000045 -0.000312   \n",
            "118  0.000045  0.000045  0.000045  0.000045   0.000045  0.000045 -0.000312   \n",
            "119  0.000045  0.000045  0.000045  0.000045   0.000045  0.000045 -0.000312   \n",
            "\n",
            "            1         2         0  ...        21        22        23  \\\n",
            "0    0.001244  0.998579  0.113429  ... -0.000029  0.000529  0.000695   \n",
            "1    0.001244  0.998579  0.113429  ... -0.000029  0.000529  0.000695   \n",
            "2    0.001244  0.998579  0.113429  ... -0.000029  0.000529  0.000695   \n",
            "3    0.001244  0.998579  0.113429  ... -0.000029  0.000529  0.000695   \n",
            "4    0.001244  0.998579  0.113429  ... -0.000029  0.000529  0.000695   \n",
            "..        ...       ...       ...  ...       ...       ...       ...   \n",
            "115  0.001244  0.998579  0.113429  ... -0.000029  0.000529  0.000695   \n",
            "116  0.001244  0.998579  0.113429  ... -0.000029  0.000529  0.000695   \n",
            "117  0.001244  0.998579  0.113429  ... -0.000029  0.000529  0.000695   \n",
            "118  0.001244  0.998579  0.113429  ... -0.000029  0.000529  0.000695   \n",
            "119  0.001244  0.998579  0.113429  ... -0.000029  0.000529  0.000695   \n",
            "\n",
            "           24        25        26        27        28        29        30  \n",
            "0    0.000463  0.000337  0.001225  0.002675  0.002135  0.001946  0.014134  \n",
            "1    0.000463  0.000337  0.001225  0.002675  0.002135  0.001946  0.014134  \n",
            "2    0.000463  0.000337  0.001225  0.002675  0.002135  0.001946  0.014134  \n",
            "3    0.000463  0.000337  0.001225  0.002675  0.002135  0.001946  0.014134  \n",
            "4    0.000463  0.000337  0.001225  0.002675  0.002135  0.001946  0.014134  \n",
            "..        ...       ...       ...       ...       ...       ...       ...  \n",
            "115  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946  0.014134  \n",
            "116  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946  0.014134  \n",
            "117  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946  0.014134  \n",
            "118  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946  0.014134  \n",
            "119  0.000463  0.000337  0.001225  0.002675  0.002135  0.001946  0.014134  \n",
            "\n",
            "[120 rows x 40 columns]\n",
            "       Actual  Predicted\n",
            "0    0.000514   0.000045\n",
            "1    0.000514   0.000045\n",
            "2    0.000514   0.000045\n",
            "3    0.000514   0.000045\n",
            "4    0.000514   0.000045\n",
            "..        ...        ...\n",
            "115  0.000514   0.000045\n",
            "116  0.000514   0.000045\n",
            "117  0.000514   0.000045\n",
            "118  0.000514   0.000045\n",
            "119  0.000514   0.000045\n",
            "\n",
            "[120 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'JOL-USD': (0.0005139758, 4.973356814681912e-05)}\n",
            "HDV\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['HDV-BTC']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HDV\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['HDV-ETH']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HDV\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Open      High       Low     Close  Adj Close        Volume     10  \\\n",
            "0     0.000129  0.000129  0.000129  0.000129   0.000129  1.000000e-09   True   \n",
            "1     0.000129  0.000129  0.000129  0.000129   0.000129  1.000000e-09   True   \n",
            "2     0.000129  0.000129  0.000129  0.000129   0.000129  1.000000e-09   True   \n",
            "3     0.000129  0.000129  0.000129  0.000129   0.000129  1.000000e-09   True   \n",
            "4     0.000129  0.000129  0.000129  0.000129   0.000129  1.000000e-09   True   \n",
            "...        ...       ...       ...       ...        ...           ...    ...   \n",
            "5754  0.000134  0.000134  0.000134  0.000134   0.000134  1.000000e-09  False   \n",
            "5755  0.000134  0.000134  0.000134  0.000134   0.000134  1.000000e+00  False   \n",
            "5756  0.000134  0.000134  0.000134  0.000134   0.000134  6.100000e+01  False   \n",
            "5757  0.000134  0.000134  0.000134  0.000134   0.000134  1.000000e-09  False   \n",
            "5758  0.000134  0.000134  0.000134  0.000134   0.000134  1.000000e-09  False   \n",
            "\n",
            "         11     12      1  ...     22     23     24     25     26     27  \\\n",
            "0     False  False  False  ...  False  False  False  False  False  False   \n",
            "1     False  False  False  ...  False  False  False  False  False  False   \n",
            "2     False  False  False  ...  False  False  False  False  False  False   \n",
            "3     False  False  False  ...  False  False  False  False  False  False   \n",
            "4     False  False  False  ...  False  False  False  False  False  False   \n",
            "...     ...    ...    ...  ...    ...    ...    ...    ...    ...    ...   \n",
            "5754  False   True  False  ...  False  False  False  False  False  False   \n",
            "5755  False   True  False  ...  False  False  False  False  False  False   \n",
            "5756  False   True  False  ...  False  False  False  False  False  False   \n",
            "5757  False   True  False  ...  False  False  False  False  False  False   \n",
            "5758  False   True  False  ...  False  False  False  False  False  False   \n",
            "\n",
            "         28     29     30     31  \n",
            "0     False  False  False  False  \n",
            "1     False  False  False  False  \n",
            "2     False  False  False  False  \n",
            "3     False  False  False  False  \n",
            "4     False  False  False  False  \n",
            "...     ...    ...    ...    ...  \n",
            "5754  False  False  False  False  \n",
            "5755  False  False  False  False  \n",
            "5756  False  False  False  False  \n",
            "5757  False  False  False  False  \n",
            "5758  False  False  False  False  \n",
            "\n",
            "[5759 rows x 40 columns]\n",
            "          Open      High       Low     Close  Adj Close        Volume     10  \\\n",
            "0     0.000129  0.000129  0.000129  0.000129   0.000129  1.000000e-09   True   \n",
            "1     0.000129  0.000129  0.000129  0.000129   0.000129  1.000000e-09   True   \n",
            "2     0.000129  0.000129  0.000129  0.000129   0.000129  1.000000e-09   True   \n",
            "3     0.000129  0.000129  0.000129  0.000129   0.000129  1.000000e-09   True   \n",
            "4     0.000129  0.000129  0.000129  0.000129   0.000129  1.000000e-09   True   \n",
            "...        ...       ...       ...       ...        ...           ...    ...   \n",
            "5754  0.000134  0.000134  0.000134  0.000134   0.000134  1.000000e-09  False   \n",
            "5755  0.000134  0.000134  0.000134  0.000134   0.000134  1.000000e+00  False   \n",
            "5756  0.000134  0.000134  0.000134  0.000134   0.000134  6.100000e+01  False   \n",
            "5757  0.000134  0.000134  0.000134  0.000134   0.000134  1.000000e-09  False   \n",
            "5758  0.000134  0.000134  0.000134  0.000134   0.000134  1.000000e-09  False   \n",
            "\n",
            "         11     12      1  ...     22     23     24     25     26     27  \\\n",
            "0     False  False  False  ...  False  False  False  False  False  False   \n",
            "1     False  False  False  ...  False  False  False  False  False  False   \n",
            "2     False  False  False  ...  False  False  False  False  False  False   \n",
            "3     False  False  False  ...  False  False  False  False  False  False   \n",
            "4     False  False  False  ...  False  False  False  False  False  False   \n",
            "...     ...    ...    ...  ...    ...    ...    ...    ...    ...    ...   \n",
            "5754  False   True  False  ...  False  False  False  False  False  False   \n",
            "5755  False   True  False  ...  False  False  False  False  False  False   \n",
            "5756  False   True  False  ...  False  False  False  False  False  False   \n",
            "5757  False   True  False  ...  False  False  False  False  False  False   \n",
            "5758  False   True  False  ...  False  False  False  False  False  False   \n",
            "\n",
            "         28     29     30     31  \n",
            "0     False  False  False  False  \n",
            "1     False  False  False  False  \n",
            "2     False  False  False  False  \n",
            "3     False  False  False  False  \n",
            "4     False  False  False  False  \n",
            "...     ...    ...    ...    ...  \n",
            "5754  False  False  False  False  \n",
            "5755  False  False  False  False  \n",
            "5756  False  False  False  False  \n",
            "5757  False  False  False  False  \n",
            "5758  False  False  False  False  \n",
            "\n",
            "[5392 rows x 40 columns]\n",
            "       Actual\n",
            "0    0.000126\n",
            "1    0.000126\n",
            "2    0.000126\n",
            "3    0.000126\n",
            "4    0.000126\n",
            "..        ...\n",
            "115  0.000134\n",
            "116  0.000134\n",
            "117  0.000134\n",
            "118  0.000134\n",
            "119  0.000134\n",
            "\n",
            "[120 rows x 1 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:70: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "<ipython-input-7-2acd743933a4>:77: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  test[i]=s_s\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d (\u001b[38;5;33mConv1D\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                     \u001b[38;5;34m30,976\u001b[0m \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " average_pooling1d (\u001b[38;5;33mAveragePooling1D\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                    \u001b[38;5;34m196,864\u001b[0m \n",
              "\n",
              " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " average_pooling1d_1                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mAveragePooling1D\u001b[0m)                                                                 \n",
              "\n",
              " lstm (\u001b[38;5;33mLSTM\u001b[0m)                           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                       \u001b[38;5;34m5,028,000\u001b[0m \n",
              "\n",
              " repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " Multi-Head (\u001b[38;5;33mMultiHeadAttention\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                    \u001b[38;5;34m4,004,000\u001b[0m \n",
              "\n",
              " lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1000\u001b[0m)                    \u001b[38;5;34m8,004,000\u001b[0m \n",
              "\n",
              " time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m40\u001b[0m)                         \u001b[38;5;34m40,040\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">30,976</span> \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " average_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> \n",
              "\n",
              " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " average_pooling1d_1                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)                                                                 \n",
              "\n",
              " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,028,000</span> \n",
              "\n",
              " repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " Multi-Head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">4,004,000</span> \n",
              "\n",
              " lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">8,004,000</span> \n",
              "\n",
              " time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">40,040</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,303,880\u001b[0m (66.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,303,880</span> (66.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,303,880\u001b[0m (66.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,303,880</span> (66.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 99ms/step - loss: 0.0632 - root_mean_squared_error: 0.2512 - val_loss: 0.0834 - val_root_mean_squared_error: 0.2887 - learning_rate: 0.0020\n",
            "Epoch 2/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0665 - root_mean_squared_error: 0.2579 - val_loss: 0.0790 - val_root_mean_squared_error: 0.2810 - learning_rate: 0.0020\n",
            "Epoch 3/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - loss: 0.0554 - root_mean_squared_error: 0.2354 - val_loss: 0.0799 - val_root_mean_squared_error: 0.2826 - learning_rate: 0.0020\n",
            "Epoch 4/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 171ms/step - loss: 0.0568 - root_mean_squared_error: 0.2382 - val_loss: 0.0841 - val_root_mean_squared_error: 0.2900 - learning_rate: 0.0020\n",
            "Epoch 5/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.0582 - root_mean_squared_error: 0.2411 - val_loss: 0.0852 - val_root_mean_squared_error: 0.2918 - learning_rate: 0.0020\n",
            "Epoch 6/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0626 - root_mean_squared_error: 0.2501 - val_loss: 0.1015 - val_root_mean_squared_error: 0.3185 - learning_rate: 0.0020\n",
            "Epoch 7/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0588 - root_mean_squared_error: 0.2425 - val_loss: 0.0989 - val_root_mean_squared_error: 0.3146 - learning_rate: 0.0020\n",
            "Epoch 8/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0583 - root_mean_squared_error: 0.2415 - val_loss: 0.0994 - val_root_mean_squared_error: 0.3153 - learning_rate: 0.0020\n",
            "Epoch 9/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0570 - root_mean_squared_error: 0.2387 - val_loss: 0.0945 - val_root_mean_squared_error: 0.3074 - learning_rate: 0.0020\n",
            "Epoch 10/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0586 - root_mean_squared_error: 0.2419 - val_loss: 0.0970 - val_root_mean_squared_error: 0.3115 - learning_rate: 0.0020\n",
            "Epoch 11/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0573 - root_mean_squared_error: 0.2394 - val_loss: 0.0982 - val_root_mean_squared_error: 0.3134 - learning_rate: 0.0020\n",
            "Epoch 12/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0587 - root_mean_squared_error: 0.2421 - val_loss: 0.1008 - val_root_mean_squared_error: 0.3175 - learning_rate: 0.0020\n",
            "Epoch 13/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0563 - root_mean_squared_error: 0.2372 - val_loss: 0.0998 - val_root_mean_squared_error: 0.3159 - learning_rate: 0.0020\n",
            "Epoch 14/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0572 - root_mean_squared_error: 0.2392 - val_loss: 0.0734 - val_root_mean_squared_error: 0.2709 - learning_rate: 0.0020\n",
            "Epoch 15/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0605 - root_mean_squared_error: 0.2460 - val_loss: 0.0424 - val_root_mean_squared_error: 0.2060 - learning_rate: 0.0020\n",
            "Epoch 16/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0625 - root_mean_squared_error: 0.2499 - val_loss: 0.0562 - val_root_mean_squared_error: 0.2370 - learning_rate: 0.0020\n",
            "Epoch 17/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0583 - root_mean_squared_error: 0.2415 - val_loss: 0.0957 - val_root_mean_squared_error: 0.3094 - learning_rate: 0.0020\n",
            "Epoch 18/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0589 - root_mean_squared_error: 0.2427 - val_loss: 0.0972 - val_root_mean_squared_error: 0.3118 - learning_rate: 0.0020\n",
            "Epoch 19/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0590 - root_mean_squared_error: 0.2428 - val_loss: 0.0756 - val_root_mean_squared_error: 0.2750 - learning_rate: 0.0020\n",
            "Epoch 20/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0584 - root_mean_squared_error: 0.2416 - val_loss: 0.0797 - val_root_mean_squared_error: 0.2823 - learning_rate: 0.0020\n",
            "Epoch 21/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0584 - root_mean_squared_error: 0.2417 - val_loss: 0.0449 - val_root_mean_squared_error: 0.2120 - learning_rate: 0.0020\n",
            "Epoch 22/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0594 - root_mean_squared_error: 0.2437 - val_loss: 0.0505 - val_root_mean_squared_error: 0.2247 - learning_rate: 0.0020\n",
            "Epoch 23/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0578 - root_mean_squared_error: 0.2405 - val_loss: 0.0649 - val_root_mean_squared_error: 0.2548 - learning_rate: 0.0020\n",
            "Epoch 24/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0597 - root_mean_squared_error: 0.2443 - val_loss: 0.0512 - val_root_mean_squared_error: 0.2264 - learning_rate: 0.0020\n",
            "Epoch 25/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0563 - root_mean_squared_error: 0.2372 - val_loss: 0.0521 - val_root_mean_squared_error: 0.2283 - learning_rate: 0.0020\n",
            "Epoch 26/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0566 - root_mean_squared_error: 0.2379 - val_loss: 0.0563 - val_root_mean_squared_error: 0.2373 - learning_rate: 0.0020\n",
            "Epoch 27/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.0557 - root_mean_squared_error: 0.2361 - val_loss: 0.0868 - val_root_mean_squared_error: 0.2946 - learning_rate: 0.0020\n",
            "Epoch 28/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0573 - root_mean_squared_error: 0.2394 - val_loss: 0.0557 - val_root_mean_squared_error: 0.2359 - learning_rate: 0.0020\n",
            "Epoch 29/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0557 - root_mean_squared_error: 0.2360 - val_loss: 0.0545 - val_root_mean_squared_error: 0.2336 - learning_rate: 0.0020\n",
            "Epoch 30/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0559 - root_mean_squared_error: 0.2364 - val_loss: 0.0434 - val_root_mean_squared_error: 0.2082 - learning_rate: 0.0020\n",
            "Epoch 31/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0566 - root_mean_squared_error: 0.2379 - val_loss: 0.0563 - val_root_mean_squared_error: 0.2372 - learning_rate: 0.0020\n",
            "Epoch 32/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0540 - root_mean_squared_error: 0.2324 - val_loss: 0.0536 - val_root_mean_squared_error: 0.2315 - learning_rate: 0.0020\n",
            "Epoch 33/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0532 - root_mean_squared_error: 0.2307 - val_loss: 0.0499 - val_root_mean_squared_error: 0.2233 - learning_rate: 0.0020\n",
            "Epoch 34/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0529 - root_mean_squared_error: 0.2300 - val_loss: 0.0473 - val_root_mean_squared_error: 0.2175 - learning_rate: 0.0020\n",
            "Epoch 35/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0521 - root_mean_squared_error: 0.2283 - val_loss: 0.0461 - val_root_mean_squared_error: 0.2147 - learning_rate: 0.0020\n",
            "Epoch 36/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0506 - root_mean_squared_error: 0.2250 - val_loss: 0.0452 - val_root_mean_squared_error: 0.2125 - learning_rate: 0.0020\n",
            "Epoch 37/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0494 - root_mean_squared_error: 0.2223 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2113 - learning_rate: 0.0020\n",
            "Epoch 38/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0550 - root_mean_squared_error: 0.2344 - val_loss: 0.0445 - val_root_mean_squared_error: 0.2109 - learning_rate: 0.0020\n",
            "Epoch 39/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0504 - root_mean_squared_error: 0.2243 - val_loss: 0.0450 - val_root_mean_squared_error: 0.2121 - learning_rate: 0.0020\n",
            "Epoch 40/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0520 - root_mean_squared_error: 0.2278 - val_loss: 0.0448 - val_root_mean_squared_error: 0.2116 - learning_rate: 0.0020\n",
            "Epoch 41/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0452 - root_mean_squared_error: 0.2126 - val_loss: 0.0449 - val_root_mean_squared_error: 0.2119 - learning_rate: 0.0020\n",
            "Epoch 42/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 251ms/step - loss: 0.0427 - root_mean_squared_error: 0.2067 - val_loss: 0.0445 - val_root_mean_squared_error: 0.2111 - learning_rate: 0.0020\n",
            "Epoch 43/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - loss: 0.0412 - root_mean_squared_error: 0.2029 - val_loss: 0.0444 - val_root_mean_squared_error: 0.2106 - learning_rate: 0.0020\n",
            "Epoch 44/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 231ms/step - loss: 0.0405 - root_mean_squared_error: 0.2013 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2106 - learning_rate: 0.0020\n",
            "Epoch 45/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0392 - root_mean_squared_error: 0.1980 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2104 - learning_rate: 0.0020\n",
            "Epoch 46/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0415 - root_mean_squared_error: 0.2037 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2105 - learning_rate: 0.0020\n",
            "Epoch 47/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - loss: 0.0384 - root_mean_squared_error: 0.1959 - val_loss: 0.0441 - val_root_mean_squared_error: 0.2099 - learning_rate: 0.0020\n",
            "Epoch 48/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - loss: 0.0391 - root_mean_squared_error: 0.1978 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2098 - learning_rate: 0.0020\n",
            "Epoch 49/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0390 - root_mean_squared_error: 0.1975 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2095 - learning_rate: 0.0020\n",
            "Epoch 50/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0388 - root_mean_squared_error: 0.1971 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2099 - learning_rate: 0.0020\n",
            "Epoch 51/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0391 - root_mean_squared_error: 0.1978 - val_loss: 0.0441 - val_root_mean_squared_error: 0.2101 - learning_rate: 0.0020\n",
            "Epoch 52/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0384 - root_mean_squared_error: 0.1959 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2099 - learning_rate: 0.0020\n",
            "Epoch 53/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0384 - root_mean_squared_error: 0.1959 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2097 - learning_rate: 0.0020\n",
            "Epoch 54/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.0380 - root_mean_squared_error: 0.1949 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 55/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0379 - root_mean_squared_error: 0.1948 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093 - learning_rate: 0.0020\n",
            "Epoch 56/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0378 - root_mean_squared_error: 0.1943 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093 - learning_rate: 0.0020\n",
            "Epoch 57/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 58/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0378 - root_mean_squared_error: 0.1945 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 59/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 217ms/step - loss: 0.0376 - root_mean_squared_error: 0.1939 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 60/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0375 - root_mean_squared_error: 0.1937 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090 - learning_rate: 0.0020\n",
            "Epoch 61/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093 - learning_rate: 0.0020\n",
            "Epoch 62/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0378 - root_mean_squared_error: 0.1943 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 63/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093 - learning_rate: 0.0020\n",
            "Epoch 64/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.0379 - root_mean_squared_error: 0.1946 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 65/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0384 - root_mean_squared_error: 0.1960 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 66/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0376 - root_mean_squared_error: 0.1940 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093 - learning_rate: 0.0020\n",
            "Epoch 67/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0379 - root_mean_squared_error: 0.1947 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2095 - learning_rate: 0.0020\n",
            "Epoch 68/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0381 - root_mean_squared_error: 0.1951 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 69/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0382 - root_mean_squared_error: 0.1955 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093 - learning_rate: 0.0020\n",
            "Epoch 70/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0384 - root_mean_squared_error: 0.1959 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2095 - learning_rate: 0.0020\n",
            "Epoch 71/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0376 - root_mean_squared_error: 0.1939 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093 - learning_rate: 0.0020\n",
            "Epoch 72/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0376 - root_mean_squared_error: 0.1938 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 73/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0384 - root_mean_squared_error: 0.1960 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093 - learning_rate: 0.0020\n",
            "Epoch 74/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0380 - root_mean_squared_error: 0.1949 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2097 - learning_rate: 0.0020\n",
            "Epoch 75/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0376 - root_mean_squared_error: 0.1940 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093 - learning_rate: 0.0020\n",
            "Epoch 76/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0374 - root_mean_squared_error: 0.1935 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 77/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 250ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 78/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0375 - root_mean_squared_error: 0.1936 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 79/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0372 - root_mean_squared_error: 0.1929 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093 - learning_rate: 0.0020\n",
            "Epoch 80/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - loss: 0.0372 - root_mean_squared_error: 0.1928 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090 - learning_rate: 0.0020\n",
            "Epoch 81/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 210ms/step - loss: 0.0371 - root_mean_squared_error: 0.1926 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 82/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0371 - root_mean_squared_error: 0.1927 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090 - learning_rate: 0.0020\n",
            "Epoch 83/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0371 - root_mean_squared_error: 0.1925 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 84/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0371 - root_mean_squared_error: 0.1926 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2089 - learning_rate: 0.0020\n",
            "Epoch 85/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0371 - root_mean_squared_error: 0.1927 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 86/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0372 - root_mean_squared_error: 0.1929 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2091 - learning_rate: 0.0020\n",
            "Epoch 87/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0371 - root_mean_squared_error: 0.1927 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 88/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0372 - root_mean_squared_error: 0.1928 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 89/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0372 - root_mean_squared_error: 0.1929 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 90/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0372 - root_mean_squared_error: 0.1929 - val_loss: 0.0441 - val_root_mean_squared_error: 0.2100 - learning_rate: 0.0020\n",
            "Epoch 91/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.0371 - root_mean_squared_error: 0.1926 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2098 - learning_rate: 0.0020\n",
            "Epoch 92/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0371 - root_mean_squared_error: 0.1925 - val_loss: 0.0440 - val_root_mean_squared_error: 0.2098 - learning_rate: 0.0020\n",
            "Epoch 93/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0372 - root_mean_squared_error: 0.1927 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2093 - learning_rate: 0.0020\n",
            "Epoch 94/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 95/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0373 - root_mean_squared_error: 0.1930 - val_loss: 0.0435 - val_root_mean_squared_error: 0.2086 - learning_rate: 0.0020\n",
            "Epoch 96/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0374 - root_mean_squared_error: 0.1933 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 97/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0373 - root_mean_squared_error: 0.1931 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2088 - learning_rate: 0.0020\n",
            "Epoch 98/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0373 - root_mean_squared_error: 0.1931 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 99/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0370 - root_mean_squared_error: 0.1922 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090 - learning_rate: 0.0020\n",
            "Epoch 100/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 309ms/step - loss: 0.0368 - root_mean_squared_error: 0.1918 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 101/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 0.0368 - root_mean_squared_error: 0.1918 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090 - learning_rate: 0.0020\n",
            "Epoch 102/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0371 - root_mean_squared_error: 0.1926 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 103/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0372 - root_mean_squared_error: 0.1929 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 104/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 105/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0375 - root_mean_squared_error: 0.1935 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 106/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0371 - root_mean_squared_error: 0.1927 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 107/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0370 - root_mean_squared_error: 0.1924 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 108/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0370 - root_mean_squared_error: 0.1924 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2095 - learning_rate: 0.0020\n",
            "Epoch 109/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0370 - root_mean_squared_error: 0.1924 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2096 - learning_rate: 0.0020\n",
            "Epoch 110/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0371 - root_mean_squared_error: 0.1925 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2089 - learning_rate: 0.0020\n",
            "Epoch 111/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0370 - root_mean_squared_error: 0.1922 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2096 - learning_rate: 0.0020\n",
            "Epoch 112/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 0.0369 - root_mean_squared_error: 0.1921 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 113/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0366 - root_mean_squared_error: 0.1913 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 114/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0370 - root_mean_squared_error: 0.1922 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2091 - learning_rate: 0.0020\n",
            "Epoch 115/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0368 - root_mean_squared_error: 0.1917 - val_loss: 0.0439 - val_root_mean_squared_error: 0.2094 - learning_rate: 0.0020\n",
            "Epoch 116/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0367 - root_mean_squared_error: 0.1916 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2091 - learning_rate: 0.0020\n",
            "Epoch 117/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0367 - root_mean_squared_error: 0.1915 - val_loss: 0.0438 - val_root_mean_squared_error: 0.2092 - learning_rate: 0.0020\n",
            "Epoch 118/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.0368 - root_mean_squared_error: 0.1918 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2091 - learning_rate: 0.0020\n",
            "Epoch 119/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0371 - root_mean_squared_error: 0.1926 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2091 - learning_rate: 0.0020\n",
            "Epoch 120/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0371 - root_mean_squared_error: 0.1926 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090 - learning_rate: 0.0020\n",
            "Epoch 121/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0369 - root_mean_squared_error: 0.1920 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090 - learning_rate: 0.0020\n",
            "Epoch 122/200\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0381 - root_mean_squared_error: 0.1951 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090 - learning_rate: 0.0020\n",
            "Epoch 123/200\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "dict_output = {}\n",
        "\n",
        "for i in range(100):\n",
        "  n = random.randint(0,len(cryptos))\n",
        "  for j in ['BTC', 'ETH', 'USD']:\n",
        "    #n = i\n",
        "    print(cryptos[n])\n",
        "    dict_output = getFuturePrices(cryptos[n], j, dict_output, 30, '2011-01-01', '2024-12-08')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahwgu3M2C5o3"
      },
      "outputs": [],
      "source": [
        "dict_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ra_KLl-X-1DX"
      },
      "outputs": [],
      "source": [
        "dict_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B1zEGPVjDG8"
      },
      "outputs": [],
      "source": [
        "dict_output = {}\n",
        "dict_output = getFuturePrices('BLOB', 'USD', dict_output, 20, '2011-01-01', '2024-07-16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1tzLJcqY95R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}